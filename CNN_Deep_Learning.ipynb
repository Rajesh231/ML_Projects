{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPool1D,Flatten,Dense,Dropout,BatchNormalization\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.feature_selection import variance_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dport</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.055572</td>\n",
       "      <td>1</td>\n",
       "      <td>13485</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.097566</td>\n",
       "      <td>1</td>\n",
       "      <td>35155</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>474</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3598.238525</td>\n",
       "      <td>1</td>\n",
       "      <td>43565</td>\n",
       "      <td>23</td>\n",
       "      <td>876</td>\n",
       "      <td>96819</td>\n",
       "      <td>47731</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3591.619629</td>\n",
       "      <td>1</td>\n",
       "      <td>43565</td>\n",
       "      <td>23</td>\n",
       "      <td>867</td>\n",
       "      <td>95866</td>\n",
       "      <td>47068</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1337.931763</td>\n",
       "      <td>1</td>\n",
       "      <td>44774</td>\n",
       "      <td>23</td>\n",
       "      <td>275</td>\n",
       "      <td>28434</td>\n",
       "      <td>12099</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dur  Proto  Sport  Dport  TotPkts  TotBytes  SrcBytes  Label  State\n",
       "0     0.055572      1  13485      1        2       128        60      0      1\n",
       "1     0.097566      1  35155     10        2       474       145      0      1\n",
       "2  3598.238525      1  43565     23      876     96819     47731      0      1\n",
       "3  3591.619629      1  43565     23      867     95866     47068      0      1\n",
       "4  1337.931763      1  44774     23      275     28434     12099      0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\Rajesh\\OneDrive\\Documents\\finalpreprocessed2.csv\") \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025681 entries, 0 to 1025680\n",
      "Data columns (total 9 columns):\n",
      "Dur         1025681 non-null float64\n",
      "Proto       1025681 non-null int64\n",
      "Sport       1025681 non-null int64\n",
      "Dport       1025681 non-null int64\n",
      "TotPkts     1025681 non-null int64\n",
      "TotBytes    1025681 non-null int64\n",
      "SrcBytes    1025681 non-null int64\n",
      "Label       1025681 non-null int64\n",
      "State       1025681 non-null int64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 70.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1025681, 9)\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1025681 entries, 0 to 1025680\n",
      "Data columns (total 9 columns):\n",
      "Dur         1025681 non-null float64\n",
      "Proto       1025681 non-null int64\n",
      "Sport       1025681 non-null int64\n",
      "Dport       1025681 non-null int64\n",
      "TotPkts     1025681 non-null int64\n",
      "TotBytes    1025681 non-null int64\n",
      "SrcBytes    1025681 non-null int64\n",
      "Label       1025681 non-null int64\n",
      "State       1025681 non-null int64\n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 70.4 MB\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(\"\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026917408559906125\n",
      "\n",
      "\n",
      "Fraud Cases: 26885\n",
      "Valid Transactions: 998796\n"
     ]
    }
   ],
   "source": [
    "# Determine number of fraud cases in dataset \n",
    "Botnet= df[df['Label'] == 1] \n",
    "Normal = df[df['Label'] == 0] \n",
    "outlierFraction = len(Botnet)/float(len(Normal)) \n",
    "print(outlierFraction) \n",
    "print(\"\\n\")\n",
    "print('Fraud Cases: {}'.format(len(df[df['Label'] == 1]))) \n",
    "print('Valid Transactions: {}'.format(len(df[df['Label'] == 0]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount details of the Botnet Traffic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dport</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.000000</td>\n",
       "      <td>26885.0</td>\n",
       "      <td>26885.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>9.250071</td>\n",
       "      <td>1.196913</td>\n",
       "      <td>2231.884545</td>\n",
       "      <td>412.839316</td>\n",
       "      <td>3.969797</td>\n",
       "      <td>549.570504</td>\n",
       "      <td>206.900800</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.895890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>103.058563</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>638.083492</td>\n",
       "      <td>3525.908075</td>\n",
       "      <td>102.435016</td>\n",
       "      <td>9708.380705</td>\n",
       "      <td>4122.435199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.259859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1025.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.019557</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2077.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.066952</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2077.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.310549</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2079.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3599.943115</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>65520.000000</td>\n",
       "      <td>8645.000000</td>\n",
       "      <td>790233.000000</td>\n",
       "      <td>258900.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Dur         Proto         Sport         Dport       TotPkts  \\\n",
       "count  26885.000000  26885.000000  26885.000000  26885.000000  26885.000000   \n",
       "mean       9.250071      1.196913   2231.884545    412.839316      3.969797   \n",
       "std      103.058563      0.397673    638.083492   3525.908075    102.435016   \n",
       "min        0.000000      1.000000   1025.000000     25.000000      1.000000   \n",
       "25%        0.019557      1.000000   2077.000000     53.000000      2.000000   \n",
       "50%        0.066952      1.000000   2077.000000     53.000000      2.000000   \n",
       "75%        0.310549      1.000000   2079.000000     53.000000      2.000000   \n",
       "max     3599.943115      2.000000   5000.000000  65520.000000   8645.000000   \n",
       "\n",
       "            TotBytes       SrcBytes    Label         State  \n",
       "count   26885.000000   26885.000000  26885.0  26885.000000  \n",
       "mean      549.570504     206.900800      1.0      1.895890  \n",
       "std      9708.380705    4122.435199      0.0      2.259859  \n",
       "min        62.000000      62.000000      1.0      1.000000  \n",
       "25%       183.000000      71.000000      1.0      1.000000  \n",
       "50%       201.000000      74.000000      1.0      1.000000  \n",
       "75%       260.000000      80.000000      1.0      2.000000  \n",
       "max    790233.000000  258900.000000      1.0     22.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Amount details of the Botnet Traffic\") \n",
    "df[df['Label']==1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "details of  Normal Traffic\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dur</th>\n",
       "      <th>Proto</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Dport</th>\n",
       "      <th>TotPkts</th>\n",
       "      <th>TotBytes</th>\n",
       "      <th>SrcBytes</th>\n",
       "      <th>Label</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>998796.000000</td>\n",
       "      <td>998796.000000</td>\n",
       "      <td>998796.000000</td>\n",
       "      <td>998796.000000</td>\n",
       "      <td>9.987960e+05</td>\n",
       "      <td>9.987960e+05</td>\n",
       "      <td>9.987960e+05</td>\n",
       "      <td>998796.0</td>\n",
       "      <td>998796.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>478.425650</td>\n",
       "      <td>1.173243</td>\n",
       "      <td>37934.694771</td>\n",
       "      <td>8884.957119</td>\n",
       "      <td>2.455467e+01</td>\n",
       "      <td>1.921317e+04</td>\n",
       "      <td>4.453049e+03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.099250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1048.031140</td>\n",
       "      <td>0.425711</td>\n",
       "      <td>18781.846433</td>\n",
       "      <td>12508.066439</td>\n",
       "      <td>3.740356e+03</td>\n",
       "      <td>3.980674e+06</td>\n",
       "      <td>2.653235e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.844775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.000000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21810.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.140000e+02</td>\n",
       "      <td>7.800000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42328.000000</td>\n",
       "      <td>443.000000</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.640000e+02</td>\n",
       "      <td>8.200000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>11.297167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53455.000000</td>\n",
       "      <td>13363.000000</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>6.190000e+02</td>\n",
       "      <td>2.920000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>3600.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>2.686731e+06</td>\n",
       "      <td>2.689640e+09</td>\n",
       "      <td>2.635366e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Dur          Proto          Sport          Dport  \\\n",
       "count  998796.000000  998796.000000  998796.000000  998796.000000   \n",
       "mean      478.425650       1.173243   37934.694771    8884.957119   \n",
       "std      1048.031140       0.425711   18781.846433   12508.066439   \n",
       "min         0.000000       1.000000       1.000000       1.000000   \n",
       "25%         0.000309       1.000000   21810.000000      53.000000   \n",
       "50%         0.001100       1.000000   42328.000000     443.000000   \n",
       "75%        11.297167       1.000000   53455.000000   13363.000000   \n",
       "max      3600.000000       6.000000   65535.000000   65535.000000   \n",
       "\n",
       "            TotPkts      TotBytes      SrcBytes     Label          State  \n",
       "count  9.987960e+05  9.987960e+05  9.987960e+05  998796.0  998796.000000  \n",
       "mean   2.455467e+01  1.921317e+04  4.453049e+03       0.0       2.099250  \n",
       "std    3.740356e+03  3.980674e+06  2.653235e+06       0.0       2.844775  \n",
       "min    1.000000e+00  6.000000e+01  0.000000e+00       0.0       1.000000  \n",
       "25%    2.000000e+00  2.140000e+02  7.800000e+01       0.0       1.000000  \n",
       "50%    2.000000e+00  2.640000e+02  8.200000e+01       0.0       1.000000  \n",
       "75%    6.000000e+00  6.190000e+02  2.920000e+02       0.0       1.000000  \n",
       "max    2.686731e+06  2.689640e+09  2.635366e+09       0.0      22.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"details of  Normal Traffic\") \n",
    "df[df['Label']==0].describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000002A880B852E8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A8809F73C8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A880A23978>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000002A880A5BF28>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A880A96518>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A880AC5AC8>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x000002A880B050B8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A880B346A0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x000002A880B346D8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot histogram of each parameter\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "df.hist(figsize = (20,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Correlation matrix \n",
    "corrmat = df.corr() \n",
    "fig = plt.figure(figsize = (15, 15)) \n",
    "sns.heatmap(corrmat, vmax = .8, square = True) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1025681, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(labels =['Label','State'],axis =1) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified shuffling is done to divide the data in equal ration on the basis of parameter label\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.20,random_state = 0, stratify =y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(820544, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205137,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5377\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in y_test:\n",
    "  if i==1:\n",
    "    cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21508\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in y_train:\n",
    "  if i==1:\n",
    "    cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((820544, 7), (205137, 7))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold \n",
    "filter = VarianceThreshold(0.01) \n",
    "X_train = filter.fit_transform(X_train) \n",
    "X_test = filter.transform(X_test) \n",
    "X_train.shape, X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.50069123e+00, -4.09003823e-01,  1.27191267e+00, ...,\n",
       "        -5.33356055e-03, -4.70500385e-03, -1.65548494e-03],\n",
       "       [ 2.95269579e+00, -4.09003823e-01, -6.08799721e-01, ...,\n",
       "        -4.26735702e-03, -4.63198144e-03, -1.61960052e-03],\n",
       "       [-4.49697919e-01, -4.09003823e-01,  8.49697198e-01, ...,\n",
       "        -5.86666232e-03, -4.69118175e-03, -1.67735734e-03],\n",
       "       ...,\n",
       "       [-4.49677298e-01,  1.94643748e+00, -1.82357793e+00, ...,\n",
       "        -4.00080614e-03, -4.22801106e-03, -1.32979114e-03],\n",
       "       [-4.49697951e-01, -4.09003823e-01,  4.01702298e-01, ...,\n",
       "        -5.86666232e-03, -4.71908674e-03, -1.67838261e-03],\n",
       "       [-4.49698002e-01, -4.09003823e-01,  2.32898603e-01, ...,\n",
       "        -5.86666232e-03, -4.71908674e-03, -1.67838261e-03]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.49697958e-01, -4.09003823e-01, -1.59515850e-01, ...,\n",
       "        -5.86666232e-03, -4.69718002e-03, -1.67872437e-03],\n",
       "       [-4.49513184e-01, -4.09003823e-01,  1.11630804e+00, ...,\n",
       "        -5.86666232e-03, -4.71960833e-03, -1.68077491e-03],\n",
       "       [-4.49602137e-01, -4.09003823e-01, -5.04032126e-01, ...,\n",
       "        -5.86666232e-03, -4.61320425e-03, -1.68043315e-03],\n",
       "       ...,\n",
       "       [-4.49697831e-01, -4.09003823e-01,  6.82027798e-01, ...,\n",
       "        -5.86666232e-03, -4.71908674e-03, -1.67838261e-03],\n",
       "       [ 2.79941782e+00, -4.09003823e-01, -1.85090412e+00, ...,\n",
       "        -1.60184820e-03, -4.12525811e-03, -1.05741134e-03],\n",
       "       [-4.49697332e-01, -4.09003823e-01,  1.04056808e+00, ...,\n",
       "        -5.86666232e-03, -4.73942869e-03, -1.68009140e-03]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((820544, 7), (205137, 7))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(820544,7,1) \n",
    "X_test = X_test.reshape(205137,7,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((820544, 7, 1), (205137, 7, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as y is a series so y_train and y_test are also series therefore we need to convert them to a numpy array.\n",
    "y_train = y_train.to_numpy() \n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import MaxPool1D\n",
    "from keras.models import load_model\n",
    "model = Sequential()\n",
    "#model.add(LSTM(64,input_shape=(7,1),activation='relu',return_sequences=True))\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Conv1D(128,3,activation='relu',input_shape=(7,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(pool_size =2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters =256 ,kernel_size = 4,activation='relu',input_shape=(7,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(350,4,activation='relu',input_shape=(7,1))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(256,4,activation='relu',input_shape=(7,1))) \n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 4, 256)            1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 133,889\n",
      "Trainable params: 133,377\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "#model.compile(optimizer=SGD(lr=0.00000005),loss =\"binary_crossentropy\",metrics = ['f1_score'])\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "#simple early stopping and model chekcpoint functions\n",
    "es = EarlyStopping(monitor='val_loss',mode = 'min',verbose =1,patience = 75)\n",
    "mc = ModelCheckpoint(r\"C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\",monitor = 'val_loss', mode = 'min', verbose =1, save_best_only = True)\n",
    "lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 35, verbose = 0, mode = \"min\", min_delta= 1e-04, cooldown = 0,min_lr = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 549764 samples, validate on 270780 samples\n",
      "Epoch 1/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0286 - accuracy: 0.9914\n",
      "Epoch 00001: val_loss improved from inf to 0.02726, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 62s 112us/sample - loss: 0.0286 - accuracy: 0.9914 - val_loss: 0.0273 - val_accuracy: 0.9919\n",
      "Epoch 2/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0261 - accuracy: 0.9919\n",
      "Epoch 00002: val_loss improved from 0.02726 to 0.02474, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 64s 116us/sample - loss: 0.0261 - accuracy: 0.9919 - val_loss: 0.0247 - val_accuracy: 0.9921\n",
      "Epoch 3/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0252 - accuracy: 0.9921\n",
      "Epoch 00003: val_loss improved from 0.02474 to 0.02362, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 64s 116us/sample - loss: 0.0252 - accuracy: 0.9921 - val_loss: 0.0236 - val_accuracy: 0.9924\n",
      "Epoch 4/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0244 - accuracy: 0.9922\n",
      "Epoch 00004: val_loss improved from 0.02362 to 0.02164, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 65s 119us/sample - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0216 - val_accuracy: 0.9937\n",
      "Epoch 5/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0232 - accuracy: 0.9926\n",
      "Epoch 00005: val_loss improved from 0.02164 to 0.02111, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 67s 121us/sample - loss: 0.0232 - accuracy: 0.9926 - val_loss: 0.0211 - val_accuracy: 0.9930\n",
      "Epoch 6/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9927\n",
      "Epoch 00006: val_loss improved from 0.02111 to 0.02096, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 67s 121us/sample - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.0210 - val_accuracy: 0.9930\n",
      "Epoch 7/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9930\n",
      "Epoch 00007: val_loss did not improve from 0.02096\n",
      "549764/549764 [==============================] - 68s 123us/sample - loss: 0.0218 - accuracy: 0.9930 - val_loss: 0.0219 - val_accuracy: 0.9927\n",
      "Epoch 8/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0221 - accuracy: 0.9928\n",
      "Epoch 00008: val_loss improved from 0.02096 to 0.01903, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 77s 141us/sample - loss: 0.0221 - accuracy: 0.9928 - val_loss: 0.0190 - val_accuracy: 0.9938\n",
      "Epoch 9/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9931\n",
      "Epoch 00009: val_loss did not improve from 0.01903\n",
      "549764/549764 [==============================] - 78s 143us/sample - loss: 0.0211 - accuracy: 0.9931 - val_loss: 0.0211 - val_accuracy: 0.9935\n",
      "Epoch 10/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0208 - accuracy: 0.9933\n",
      "Epoch 00010: val_loss improved from 0.01903 to 0.01826, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0183 - val_accuracy: 0.9936\n",
      "Epoch 11/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9935\n",
      "Epoch 00011: val_loss did not improve from 0.01826\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0199 - val_accuracy: 0.9941\n",
      "Epoch 12/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0202 - accuracy: 0.9934\n",
      "Epoch 00012: val_loss did not improve from 0.01826\n",
      "549764/549764 [==============================] - 78s 141us/sample - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.0217 - val_accuracy: 0.9935\n",
      "Epoch 13/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0200 - accuracy: 0.9935\n",
      "Epoch 00013: val_loss improved from 0.01826 to 0.01689, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 82s 149us/sample - loss: 0.0200 - accuracy: 0.9935 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 14/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.9935\n",
      "Epoch 00014: val_loss did not improve from 0.01689\n",
      "549764/549764 [==============================] - 84s 152us/sample - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.0210 - val_accuracy: 0.9937\n",
      "Epoch 15/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.9936\n",
      "Epoch 00015: val_loss did not improve from 0.01689\n",
      "549764/549764 [==============================] - 79s 143us/sample - loss: 0.0198 - accuracy: 0.9936 - val_loss: 0.0174 - val_accuracy: 0.9939\n",
      "Epoch 16/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 00016: val_loss did not improve from 0.01689\n",
      "549764/549764 [==============================] - 78s 142us/sample - loss: 0.0189 - accuracy: 0.9937 - val_loss: 0.0184 - val_accuracy: 0.9936\n",
      "Epoch 17/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9937\n",
      "Epoch 00017: val_loss improved from 0.01689 to 0.01688, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0187 - accuracy: 0.9937 - val_loss: 0.0169 - val_accuracy: 0.9942\n",
      "Epoch 18/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9938\n",
      "Epoch 00018: val_loss improved from 0.01688 to 0.01665, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0183 - accuracy: 0.9938 - val_loss: 0.0167 - val_accuracy: 0.9939\n",
      "Epoch 19/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9938\n",
      "Epoch 00019: val_loss improved from 0.01665 to 0.01382, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 77s 139us/sample - loss: 0.0180 - accuracy: 0.9938 - val_loss: 0.0138 - val_accuracy: 0.9940\n",
      "Epoch 20/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0182 - accuracy: 0.9937\n",
      "Epoch 00020: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 92s 167us/sample - loss: 0.0182 - accuracy: 0.9937 - val_loss: 0.0173 - val_accuracy: 0.9943\n",
      "Epoch 21/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.9939\n",
      "Epoch 00021: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 96s 174us/sample - loss: 0.0177 - accuracy: 0.9939 - val_loss: 0.0156 - val_accuracy: 0.9943\n",
      "Epoch 22/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.9940\n",
      "Epoch 00022: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 100s 181us/sample - loss: 0.0175 - accuracy: 0.9940 - val_loss: 0.0162 - val_accuracy: 0.9946\n",
      "Epoch 23/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0172 - accuracy: 0.9940\n",
      "Epoch 00023: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 99s 181us/sample - loss: 0.0172 - accuracy: 0.9940 - val_loss: 0.0146 - val_accuracy: 0.9945\n",
      "Epoch 24/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9940\n",
      "Epoch 00024: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 113s 205us/sample - loss: 0.0170 - accuracy: 0.9940 - val_loss: 0.0139 - val_accuracy: 0.9948\n",
      "Epoch 25/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9939\n",
      "Epoch 00025: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 122s 221us/sample - loss: 0.0170 - accuracy: 0.9939 - val_loss: 0.0142 - val_accuracy: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0167 - accuracy: 0.9941\n",
      "Epoch 00026: val_loss did not improve from 0.01382\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0167 - accuracy: 0.9941 - val_loss: 0.0186 - val_accuracy: 0.9938\n",
      "Epoch 27/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0165 - accuracy: 0.9942\n",
      "Epoch 00027: val_loss improved from 0.01382 to 0.01365, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 118s 215us/sample - loss: 0.0165 - accuracy: 0.9942 - val_loss: 0.0136 - val_accuracy: 0.9948\n",
      "Epoch 28/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0162 - accuracy: 0.9942\n",
      "Epoch 00028: val_loss did not improve from 0.01365\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.0146 - val_accuracy: 0.9943\n",
      "Epoch 29/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9942\n",
      "Epoch 00029: val_loss did not improve from 0.01365\n",
      "549764/549764 [==============================] - 117s 214us/sample - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.0162 - val_accuracy: 0.9941\n",
      "Epoch 30/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 00030: val_loss improved from 0.01365 to 0.01283, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0128 - val_accuracy: 0.9950\n",
      "Epoch 31/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9942\n",
      "Epoch 00031: val_loss did not improve from 0.01283\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0158 - accuracy: 0.9942 - val_loss: 0.0138 - val_accuracy: 0.9949\n",
      "Epoch 32/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0159 - accuracy: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 0.01283\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0159 - accuracy: 0.9943 - val_loss: 0.0129 - val_accuracy: 0.9941\n",
      "Epoch 33/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0161 - accuracy: 0.9942\n",
      "Epoch 00033: val_loss did not improve from 0.01283\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0161 - accuracy: 0.9942 - val_loss: 0.0146 - val_accuracy: 0.9945\n",
      "Epoch 34/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9944\n",
      "Epoch 00034: val_loss improved from 0.01283 to 0.01196, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0120 - val_accuracy: 0.9946\n",
      "Epoch 35/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 00035: val_loss did not improve from 0.01196\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0160 - accuracy: 0.9943 - val_loss: 0.0152 - val_accuracy: 0.9947\n",
      "Epoch 36/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9944\n",
      "Epoch 00036: val_loss did not improve from 0.01196\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0140 - val_accuracy: 0.9942\n",
      "Epoch 37/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9944\n",
      "Epoch 00037: val_loss did not improve from 0.01196\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0154 - accuracy: 0.9944 - val_loss: 0.0122 - val_accuracy: 0.9946\n",
      "Epoch 38/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9945\n",
      "Epoch 00038: val_loss did not improve from 0.01196\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0153 - accuracy: 0.9945 - val_loss: 0.0126 - val_accuracy: 0.9952\n",
      "Epoch 39/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0153 - accuracy: 0.9944\n",
      "Epoch 00039: val_loss did not improve from 0.01196\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0153 - accuracy: 0.9944 - val_loss: 0.0128 - val_accuracy: 0.9950\n",
      "Epoch 40/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9944\n",
      "Epoch 00040: val_loss improved from 0.01196 to 0.01175, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0156 - accuracy: 0.9944 - val_loss: 0.0118 - val_accuracy: 0.9952\n",
      "Epoch 41/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9944\n",
      "Epoch 00041: val_loss did not improve from 0.01175\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0152 - accuracy: 0.9944 - val_loss: 0.0135 - val_accuracy: 0.9946\n",
      "Epoch 42/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9944\n",
      "Epoch 00042: val_loss did not improve from 0.01175\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0130 - val_accuracy: 0.9944\n",
      "Epoch 43/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 00043: val_loss did not improve from 0.01175\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0159 - val_accuracy: 0.9949\n",
      "Epoch 44/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9944\n",
      "Epoch 00044: val_loss improved from 0.01175 to 0.01129, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0151 - accuracy: 0.9944 - val_loss: 0.0113 - val_accuracy: 0.9951\n",
      "Epoch 45/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9946\n",
      "Epoch 00045: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0136 - val_accuracy: 0.9946\n",
      "Epoch 46/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 00046: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0128 - val_accuracy: 0.9943\n",
      "Epoch 47/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0149 - accuracy: 0.9945\n",
      "Epoch 00047: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0149 - accuracy: 0.9945 - val_loss: 0.0149 - val_accuracy: 0.9967\n",
      "Epoch 48/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9945\n",
      "Epoch 00048: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0147 - accuracy: 0.9945 - val_loss: 0.0145 - val_accuracy: 0.9949\n",
      "Epoch 49/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9946\n",
      "Epoch 00049: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 121s 219us/sample - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.0123 - val_accuracy: 0.9950\n",
      "Epoch 50/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9947\n",
      "Epoch 00050: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0143 - accuracy: 0.9947 - val_loss: 0.0114 - val_accuracy: 0.9948\n",
      "Epoch 51/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0145 - accuracy: 0.9947\n",
      "Epoch 00051: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 118s 215us/sample - loss: 0.0145 - accuracy: 0.9947 - val_loss: 0.0132 - val_accuracy: 0.9948\n",
      "Epoch 52/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9946\n",
      "Epoch 00052: val_loss did not improve from 0.01129\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0143 - accuracy: 0.9946 - val_loss: 0.0149 - val_accuracy: 0.9942\n",
      "Epoch 53/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 00053: val_loss improved from 0.01129 to 0.01061, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0106 - val_accuracy: 0.9948\n",
      "Epoch 54/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9948\n",
      "Epoch 00054: val_loss did not improve from 0.01061\n",
      "549764/549764 [==============================] - 121s 219us/sample - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.0112 - val_accuracy: 0.9964\n",
      "Epoch 55/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 00055: val_loss did not improve from 0.01061\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.0124 - val_accuracy: 0.9946\n",
      "Epoch 56/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9950\n",
      "Epoch 00056: val_loss did not improve from 0.01061\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0135 - accuracy: 0.9950 - val_loss: 0.0117 - val_accuracy: 0.9951\n",
      "Epoch 57/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9948\n",
      "Epoch 00057: val_loss improved from 0.01061 to 0.01060, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.0106 - val_accuracy: 0.9952\n",
      "Epoch 58/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9948\n",
      "Epoch 00058: val_loss improved from 0.01060 to 0.00946, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0140 - accuracy: 0.9948 - val_loss: 0.0095 - val_accuracy: 0.9960\n",
      "Epoch 59/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9947\n",
      "Epoch 00059: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0142 - accuracy: 0.9947 - val_loss: 0.0116 - val_accuracy: 0.9945\n",
      "Epoch 60/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9948\n",
      "Epoch 00060: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0137 - accuracy: 0.9948 - val_loss: 0.0109 - val_accuracy: 0.9949\n",
      "Epoch 61/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9949\n",
      "Epoch 00061: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0144 - val_accuracy: 0.9948\n",
      "Epoch 62/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9948\n",
      "Epoch 00062: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0141 - accuracy: 0.9948 - val_loss: 0.0105 - val_accuracy: 0.9953\n",
      "Epoch 63/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0139 - accuracy: 0.9949\n",
      "Epoch 00063: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 121s 219us/sample - loss: 0.0139 - accuracy: 0.9949 - val_loss: 0.0117 - val_accuracy: 0.9951\n",
      "Epoch 64/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9946\n",
      "Epoch 00064: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0120 - val_accuracy: 0.9952\n",
      "Epoch 65/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9946\n",
      "Epoch 00065: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.0133 - val_accuracy: 0.9942\n",
      "Epoch 66/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9948\n",
      "Epoch 00066: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0138 - accuracy: 0.9948 - val_loss: 0.0107 - val_accuracy: 0.9951\n",
      "Epoch 67/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9950\n",
      "Epoch 00067: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 118s 214us/sample - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.0133 - val_accuracy: 0.9978\n",
      "Epoch 68/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9949\n",
      "Epoch 00068: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0136 - accuracy: 0.9949 - val_loss: 0.0114 - val_accuracy: 0.9952\n",
      "Epoch 69/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9950\n",
      "Epoch 00069: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.0100 - val_accuracy: 0.9951\n",
      "Epoch 70/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9950\n",
      "Epoch 00070: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0134 - accuracy: 0.9950 - val_loss: 0.0118 - val_accuracy: 0.9976\n",
      "Epoch 71/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9950\n",
      "Epoch 00071: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0138 - accuracy: 0.9950 - val_loss: 0.0099 - val_accuracy: 0.9953\n",
      "Epoch 72/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9951\n",
      "Epoch 00072: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0133 - accuracy: 0.9951 - val_loss: 0.0097 - val_accuracy: 0.9988\n",
      "Epoch 73/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9949\n",
      "Epoch 00073: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.0110 - val_accuracy: 0.9985\n",
      "Epoch 74/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 00074: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 121s 219us/sample - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0131 - val_accuracy: 0.9982\n",
      "Epoch 75/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 00075: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0102 - val_accuracy: 0.9950\n",
      "Epoch 76/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9947\n",
      "Epoch 00076: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0141 - accuracy: 0.9947 - val_loss: 0.0113 - val_accuracy: 0.9950\n",
      "Epoch 77/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9952\n",
      "Epoch 00077: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 118s 215us/sample - loss: 0.0134 - accuracy: 0.9952 - val_loss: 0.0118 - val_accuracy: 0.9979\n",
      "Epoch 78/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9952\n",
      "Epoch 00078: val_loss did not improve from 0.00946\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0116 - val_accuracy: 0.9986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9952\n",
      "Epoch 00079: val_loss improved from 0.00946 to 0.00883, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0088 - val_accuracy: 0.9965\n",
      "Epoch 80/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9952\n",
      "Epoch 00080: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0090 - val_accuracy: 0.9978\n",
      "Epoch 81/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9953\n",
      "Epoch 00081: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0265 - val_accuracy: 0.9946\n",
      "Epoch 82/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9952\n",
      "Epoch 00082: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0130 - accuracy: 0.9952 - val_loss: 0.0110 - val_accuracy: 0.9948\n",
      "Epoch 83/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0128 - accuracy: 0.9953\n",
      "Epoch 00083: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 118s 214us/sample - loss: 0.0128 - accuracy: 0.9953 - val_loss: 0.0124 - val_accuracy: 0.9947\n",
      "Epoch 84/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9952\n",
      "Epoch 00084: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 116s 211us/sample - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0091 - val_accuracy: 0.9976\n",
      "Epoch 85/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9953\n",
      "Epoch 00085: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.0102 - val_accuracy: 0.9951\n",
      "Epoch 86/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9950\n",
      "Epoch 00086: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0136 - accuracy: 0.9950 - val_loss: 0.0125 - val_accuracy: 0.9949\n",
      "Epoch 87/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0142 - accuracy: 0.9948\n",
      "Epoch 00087: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 120s 217us/sample - loss: 0.0142 - accuracy: 0.9948 - val_loss: 0.0116 - val_accuracy: 0.9952\n",
      "Epoch 88/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9950\n",
      "Epoch 00088: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.0113 - val_accuracy: 0.9951\n",
      "Epoch 89/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9949\n",
      "Epoch 00089: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 120s 219us/sample - loss: 0.0137 - accuracy: 0.9949 - val_loss: 0.0106 - val_accuracy: 0.9953\n",
      "Epoch 90/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9951\n",
      "Epoch 00090: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0134 - accuracy: 0.9951 - val_loss: 0.0104 - val_accuracy: 0.9970\n",
      "Epoch 91/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9952\n",
      "Epoch 00091: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 116s 211us/sample - loss: 0.0129 - accuracy: 0.9952 - val_loss: 0.0126 - val_accuracy: 0.9951\n",
      "Epoch 92/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9952\n",
      "Epoch 00092: val_loss did not improve from 0.00883\n",
      "549764/549764 [==============================] - 116s 212us/sample - loss: 0.0127 - accuracy: 0.9952 - val_loss: 0.0120 - val_accuracy: 0.9980\n",
      "Epoch 93/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9952\n",
      "Epoch 00093: val_loss improved from 0.00883 to 0.00879, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0131 - accuracy: 0.9952 - val_loss: 0.0088 - val_accuracy: 0.9961\n",
      "Epoch 94/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 00094: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0134 - val_accuracy: 0.9951\n",
      "Epoch 95/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9954\n",
      "Epoch 00095: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 119s 216us/sample - loss: 0.0129 - accuracy: 0.9954 - val_loss: 0.0105 - val_accuracy: 0.9945\n",
      "Epoch 96/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 00096: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 120s 217us/sample - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0107 - val_accuracy: 0.9951\n",
      "Epoch 97/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0127 - accuracy: 0.9954\n",
      "Epoch 00097: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0127 - accuracy: 0.9954 - val_loss: 0.0178 - val_accuracy: 0.9913\n",
      "Epoch 98/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0126 - accuracy: 0.9955\n",
      "Epoch 00098: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 120s 218us/sample - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.0088 - val_accuracy: 0.9987\n",
      "Epoch 99/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9955\n",
      "Epoch 00099: val_loss did not improve from 0.00879\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.0110 - val_accuracy: 0.9950\n",
      "Epoch 100/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9957\n",
      "Epoch 00100: val_loss improved from 0.00879 to 0.00846, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 118s 214us/sample - loss: 0.0123 - accuracy: 0.9957 - val_loss: 0.0085 - val_accuracy: 0.9961\n",
      "Epoch 101/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 00101: val_loss improved from 0.00846 to 0.00824, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 117s 213us/sample - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0082 - val_accuracy: 0.9962\n",
      "Epoch 102/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 00102: val_loss did not improve from 0.00824\n",
      "549764/549764 [==============================] - 118s 215us/sample - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0086 - val_accuracy: 0.9953\n",
      "Epoch 103/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 00103: val_loss improved from 0.00824 to 0.00753, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 121s 219us/sample - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0075 - val_accuracy: 0.9982\n",
      "Epoch 104/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 00104: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 121s 220us/sample - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0084 - val_accuracy: 0.9982\n",
      "Epoch 105/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 00105: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0081 - val_accuracy: 0.9989\n",
      "Epoch 106/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 00106: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 119s 217us/sample - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.0077 - val_accuracy: 0.9976\n",
      "Epoch 107/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 00107: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 118s 215us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0099 - val_accuracy: 0.9953\n",
      "Epoch 108/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9953\n",
      "Epoch 00108: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 117s 212us/sample - loss: 0.0129 - accuracy: 0.9953 - val_loss: 0.0222 - val_accuracy: 0.9870\n",
      "Epoch 109/500\n",
      "549536/549764 [============================>.] - ETA: 4s - loss: 0.0123 - accuracy: 0.9956 \n",
      "Epoch 00109: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 11567s 21ms/sample - loss: 0.0123 - accuracy: 0.9956 - val_loss: 0.0082 - val_accuracy: 0.9985\n",
      "Epoch 110/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9957\n",
      "Epoch 00110: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 68s 124us/sample - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0079 - val_accuracy: 0.9986\n",
      "Epoch 111/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 00111: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 65s 118us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0078 - val_accuracy: 0.9979\n",
      "Epoch 112/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 00112: val_loss did not improve from 0.00753\n",
      "549764/549764 [==============================] - 64s 117us/sample - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0083 - val_accuracy: 0.9954\n",
      "Epoch 113/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 00113: val_loss improved from 0.00753 to 0.00716, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 65s 118us/sample - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0072 - val_accuracy: 0.9989\n",
      "Epoch 114/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 00114: val_loss did not improve from 0.00716\n",
      "549764/549764 [==============================] - 68s 124us/sample - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0112 - val_accuracy: 0.9963\n",
      "Epoch 115/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9960\n",
      "Epoch 00115: val_loss did not improve from 0.00716\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.0101 - val_accuracy: 0.9978\n",
      "Epoch 116/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 00116: val_loss improved from 0.00716 to 0.00659, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0066 - val_accuracy: 0.9988\n",
      "Epoch 117/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 00117: val_loss did not improve from 0.00659\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
      "Epoch 118/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961\n",
      "Epoch 00118: val_loss did not improve from 0.00659\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0083 - val_accuracy: 0.9959\n",
      "Epoch 119/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 00119: val_loss improved from 0.00659 to 0.00618, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0062 - val_accuracy: 0.9990\n",
      "Epoch 120/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9957\n",
      "Epoch 00120: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0078 - val_accuracy: 0.9984\n",
      "Epoch 121/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 00121: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 90s 165us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0081 - val_accuracy: 0.9980\n",
      "Epoch 122/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 00122: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 80s 145us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0096 - val_accuracy: 0.9951\n",
      "Epoch 123/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0131 - accuracy: 0.9951\n",
      "Epoch 00123: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.0087 - val_accuracy: 0.9975\n",
      "Epoch 124/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9960\n",
      "Epoch 00124: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.0071 - val_accuracy: 0.9989\n",
      "Epoch 125/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 00125: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0080 - val_accuracy: 0.9987\n",
      "Epoch 126/500\n",
      "549248/549764 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 00126: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0088 - val_accuracy: 0.9962\n",
      "Epoch 127/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9965\n",
      "Epoch 00127: val_loss did not improve from 0.00618\n",
      "549764/549764 [==============================] - 77s 141us/sample - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0079 - val_accuracy: 0.9953\n",
      "Epoch 128/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0108 - accuracy: 0.9964\n",
      "Epoch 00128: val_loss improved from 0.00618 to 0.00600, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 129/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0124 - accuracy: 0.9956\n",
      "Epoch 00129: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 76s 137us/sample - loss: 0.0124 - accuracy: 0.9956 - val_loss: 0.0092 - val_accuracy: 0.9949\n",
      "Epoch 130/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9961\n",
      "Epoch 00130: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.0069 - val_accuracy: 0.9982\n",
      "Epoch 131/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9963\n",
      "Epoch 00131: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0109 - accuracy: 0.9963 - val_loss: 0.0067 - val_accuracy: 0.9989\n",
      "Epoch 132/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9964\n",
      "Epoch 00132: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0092 - val_accuracy: 0.9988\n",
      "Epoch 133/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9955\n",
      "Epoch 00133: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 77s 141us/sample - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.0127 - val_accuracy: 0.9953\n",
      "Epoch 134/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9956\n",
      "Epoch 00134: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 70s 128us/sample - loss: 0.0122 - accuracy: 0.9956 - val_loss: 0.0074 - val_accuracy: 0.9984\n",
      "Epoch 135/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 00135: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 80s 146us/sample - loss: 0.0109 - accuracy: 0.9965 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 136/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 00136: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0099 - val_accuracy: 0.9951\n",
      "Epoch 137/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9956\n",
      "Epoch 00137: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.0085 - val_accuracy: 0.9954\n",
      "Epoch 138/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9956\n",
      "Epoch 00138: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 88s 161us/sample - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0075 - val_accuracy: 0.9987\n",
      "Epoch 139/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 00139: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0080 - val_accuracy: 0.9989\n",
      "Epoch 140/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0122 - accuracy: 0.9957\n",
      "Epoch 00140: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 92s 168us/sample - loss: 0.0122 - accuracy: 0.9957 - val_loss: 0.0199 - val_accuracy: 0.9859\n",
      "Epoch 141/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9958\n",
      "Epoch 00141: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.0085 - val_accuracy: 0.9960\n",
      "Epoch 142/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9960 ETA: 1s - loss: 0.0 -\n",
      "Epoch 00142: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0079 - val_accuracy: 0.9956\n",
      "Epoch 143/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 00143: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0121 - val_accuracy: 0.9953\n",
      "Epoch 144/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9960\n",
      "Epoch 00144: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.0199 - val_accuracy: 0.9952\n",
      "Epoch 145/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9959\n",
      "Epoch 00145: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0121 - val_accuracy: 0.9975\n",
      "Epoch 146/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0114 - accuracy: 0.9959\n",
      "Epoch 00146: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 85s 154us/sample - loss: 0.0114 - accuracy: 0.9959 - val_loss: 0.0098 - val_accuracy: 0.9953\n",
      "Epoch 147/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 00147: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 89s 161us/sample - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0088 - val_accuracy: 0.9954\n",
      "Epoch 148/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0129 - accuracy: 0.9955\n",
      "Epoch 00148: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.0094 - val_accuracy: 0.9984\n",
      "Epoch 149/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 00149: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0113 - accuracy: 0.9962 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 150/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9958\n",
      "Epoch 00150: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0120 - accuracy: 0.9958 - val_loss: 0.0117 - val_accuracy: 0.9952\n",
      "Epoch 151/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9960\n",
      "Epoch 00151: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0118 - accuracy: 0.9960 - val_loss: 0.0073 - val_accuracy: 0.9989\n",
      "Epoch 152/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9963\n",
      "Epoch 00152: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0091 - val_accuracy: 0.9988\n",
      "Epoch 153/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9957\n",
      "Epoch 00153: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0119 - accuracy: 0.9957 - val_loss: 0.0123 - val_accuracy: 0.9956\n",
      "Epoch 154/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9959\n",
      "Epoch 00154: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0117 - accuracy: 0.9959 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 155/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 00155: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0114 - val_accuracy: 0.9980\n",
      "Epoch 156/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 00156: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0093 - val_accuracy: 0.9953\n",
      "Epoch 157/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0116 - accuracy: 0.9959\n",
      "Epoch 00157: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 89s 161us/sample - loss: 0.0116 - accuracy: 0.9959 - val_loss: 0.0074 - val_accuracy: 0.9988\n",
      "Epoch 158/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0113 - accuracy: 0.9961\n",
      "Epoch 00158: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0113 - accuracy: 0.9961 - val_loss: 0.0064 - val_accuracy: 0.9988\n",
      "Epoch 159/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9964\n",
      "Epoch 00159: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.0069 - val_accuracy: 0.9988\n",
      "Epoch 160/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0104 - accuracy: 0.9965 ETA: 1s - loss: 0 - ETA: 1s - loss: 0.0104 - accuracy: 0. - ETA: 1s -\n",
      "Epoch 00160: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0104 - accuracy: 0.9965 - val_loss: 0.0060 - val_accuracy: 0.9989\n",
      "Epoch 161/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961\n",
      "Epoch 00161: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0073 - val_accuracy: 0.9988\n",
      "Epoch 162/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9962\n",
      "Epoch 00162: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0115 - accuracy: 0.9962 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 163/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0121 - accuracy: 0.9957\n",
      "Epoch 00163: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 84s 153us/sample - loss: 0.0121 - accuracy: 0.9957 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
      "Epoch 164/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9965\n",
      "Epoch 00164: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0100 - accuracy: 0.9965 - val_loss: 0.0077 - val_accuracy: 0.9984\n",
      "Epoch 165/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00165: val_loss did not improve from 0.00600\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0061 - val_accuracy: 0.9988\n",
      "Epoch 166/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9974\n",
      "Epoch 00166: val_loss improved from 0.00600 to 0.00592, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0082 - accuracy: 0.9974 - val_loss: 0.0059 - val_accuracy: 0.9990\n",
      "Epoch 167/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch 00167: val_loss improved from 0.00592 to 0.00559, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 168/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 00168: val_loss did not improve from 0.00559\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0060 - val_accuracy: 0.9988\n",
      "Epoch 169/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9975\n",
      "Epoch 00169: val_loss improved from 0.00559 to 0.00533, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 89s 161us/sample - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 170/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 00170: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0054 - val_accuracy: 0.9991\n",
      "Epoch 171/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 00171: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
      "Epoch 172/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 00172: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 173/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 00173: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0059 - val_accuracy: 0.9988\n",
      "Epoch 174/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 00174: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 175/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 00175: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0057 - val_accuracy: 0.9989\n",
      "Epoch 176/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 00176: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
      "Epoch 177/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9977\n",
      "Epoch 00177: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.0059 - val_accuracy: 0.9989\n",
      "Epoch 178/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9977\n",
      "Epoch 00178: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 179/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9976\n",
      "Epoch 00179: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 180/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 00180: val_loss did not improve from 0.00533\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 181/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0078 - accuracy: 0.9977\n",
      "Epoch 00181: val_loss improved from 0.00533 to 0.00522, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0052 - val_accuracy: 0.9989\n",
      "Epoch 182/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00182: val_loss improved from 0.00522 to 0.00517, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 91s 166us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0052 - val_accuracy: 0.9991\n",
      "Epoch 183/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00183: val_loss improved from 0.00517 to 0.00515, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 91s 165us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0052 - val_accuracy: 0.9989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "549248/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00184: val_loss improved from 0.00515 to 0.00514, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 185/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 00185: val_loss did not improve from 0.00514\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0061 - val_accuracy: 0.9989\n",
      "Epoch 186/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00186: val_loss improved from 0.00514 to 0.00507, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9989\n",
      "Epoch 187/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 00187: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0053 - val_accuracy: 0.9989\n",
      "Epoch 188/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9977\n",
      "Epoch 00188: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 72s 132us/sample - loss: 0.0075 - accuracy: 0.9977 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 189/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 00189: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0055 - val_accuracy: 0.9989\n",
      "Epoch 190/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9977\n",
      "Epoch 00190: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Epoch 191/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0072 - accuracy: 0.9978\n",
      "Epoch 00191: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 82s 149us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 192/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00192: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
      "Epoch 193/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00193: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0054 - val_accuracy: 0.9989\n",
      "Epoch 194/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0073 - accuracy: 0.9978\n",
      "Epoch 00194: val_loss improved from 0.00507 to 0.00507, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 195/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 00195: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 78s 141us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 196/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9979\n",
      "Epoch 00196: val_loss did not improve from 0.00507\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 197/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0074 - accuracy: 0.9979\n",
      "Epoch 00197: val_loss improved from 0.00507 to 0.00497, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0050 - val_accuracy: 0.9991\n",
      "Epoch 198/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00198: val_loss did not improve from 0.00497\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0056 - val_accuracy: 0.9990\n",
      "Epoch 199/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
      "Epoch 00199: val_loss did not improve from 0.00497\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 200/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00200: val_loss did not improve from 0.00497\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 201/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 00201: val_loss improved from 0.00497 to 0.00485, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 202/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9980\n",
      "Epoch 00202: val_loss did not improve from 0.00485\n",
      "549764/549764 [==============================] - 90s 163us/sample - loss: 0.0069 - accuracy: 0.9980 - val_loss: 0.0051 - val_accuracy: 0.9990\n",
      "Epoch 203/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 00203: val_loss did not improve from 0.00485\n",
      "549764/549764 [==============================] - 92s 166us/sample - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 204/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00204: val_loss improved from 0.00485 to 0.00476, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 90s 164us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 205/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9981\n",
      "Epoch 00205: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0054 - val_accuracy: 0.9990\n",
      "Epoch 206/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9981\n",
      "Epoch 00206: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 89s 163us/sample - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 207/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00207: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 91s 165us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 208/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00208: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 79s 144us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 209/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00209: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00210: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 211/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00211: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 212/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 00212: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 84s 152us/sample - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.0052 - val_accuracy: 0.9990\n",
      "Epoch 213/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00213: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 214/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9980\n",
      "Epoch 00214: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 95s 172us/sample - loss: 0.0068 - accuracy: 0.9980 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 215/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0067 - accuracy: 0.9981\n",
      "Epoch 00215: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 88s 159us/sample - loss: 0.0067 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9990\n",
      "Epoch 216/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00216: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 90s 164us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 217/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00217: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 85s 154us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9990\n",
      "Epoch 218/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00218: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 90s 164us/sample - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0055 - val_accuracy: 0.9990\n",
      "Epoch 219/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00219: val_loss did not improve from 0.00476\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0056 - val_accuracy: 0.9989\n",
      "Epoch 220/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00220: val_loss improved from 0.00476 to 0.00474, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 221/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 00221: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 80s 146us/sample - loss: 0.0065 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 222/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00222: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 223/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00223: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "Epoch 224/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00224: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 225/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00225: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 226/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00226: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0053 - val_accuracy: 0.9990\n",
      "Epoch 227/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00227: val_loss did not improve from 0.00474\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 228/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00228: val_loss improved from 0.00474 to 0.00468, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 91s 166us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 229/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982 ETA: 0s - loss: 0.0065 - accuracy: \n",
      "Epoch 00229: val_loss improved from 0.00468 to 0.00457, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 88s 161us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 230/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00230: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 231/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00231: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9991\n",
      "Epoch 232/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00232: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 233/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00233: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 80s 146us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 234/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9983\n",
      "Epoch 00234: val_loss improved from 0.00457 to 0.00457, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0065 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 235/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 00235: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 91s 165us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 236/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00236: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 85s 155us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9990\n",
      "Epoch 237/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00237: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 238/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00238: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 83s 151us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 239/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9982\n",
      "Epoch 00239: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 128us/sample - loss: 0.0066 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 240/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00240: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 241/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 00241: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 64s 117us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0051 - val_accuracy: 0.9991\n",
      "Epoch 242/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 00242: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 63s 115us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 243/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9983\n",
      "Epoch 00243: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 63s 114us/sample - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 244/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00244: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 64s 117us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 245/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00245: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 246/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00246: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 83s 150us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 247/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00247: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 248/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00248: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 128us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 249/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 00249: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 127us/sample - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0051 - val_accuracy: 0.9992\n",
      "Epoch 250/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00250: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 127us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 251/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00251: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 252/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00252: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 253/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0068 - accuracy: 0.9982\n",
      "Epoch 00253: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 129us/sample - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 254/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 00254: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 127us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 255/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00255: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 256/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00256: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 127us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 257/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9982\n",
      "Epoch 00257: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 69s 126us/sample - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 258/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 00258: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 69s 126us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 259/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00259: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 70s 128us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 260/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00260: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0063 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 261/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00261: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 262/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9983\n",
      "Epoch 00262: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 113s 206us/sample - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0049 - val_accuracy: 0.9991\n",
      "Epoch 263/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00263: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 71s 128us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9982\n",
      "Epoch 00264: val_loss did not improve from 0.00457\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 265/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00265: val_loss improved from 0.00457 to 0.00456, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 266/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00266: val_loss did not improve from 0.00456\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 267/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9983\n",
      "Epoch 00267: val_loss improved from 0.00456 to 0.00450, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 71s 130us/sample - loss: 0.0060 - accuracy: 0.9983 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 268/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00268: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 92s 168us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 269/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00269: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 69s 126us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 270/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00270: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 70s 128us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 271/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00271: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 272/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00272: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 273/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00273: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 274/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00274: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 275/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00275: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 276/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00276: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 277/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9984\n",
      "Epoch 00277: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 278/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00278: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 279/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00279: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 280/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00280: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 281/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00281: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 282/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00282: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 283/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00283: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 284/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00284: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0083 - val_accuracy: 0.9982\n",
      "Epoch 285/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00285: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 286/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984 ETA: 1s -\n",
      "Epoch 00286: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 287/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00287: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 288/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00288: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 289/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00289: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 290/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00290: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00291: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 292/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00292: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 293/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00293: val_loss improved from 0.00450 to 0.00450, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 294/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00294: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 295/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00295: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 134us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 296/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00296: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 297/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00297: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 298/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00298: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 299/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00299: val_loss did not improve from 0.00450\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 300/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00300: val_loss improved from 0.00450 to 0.00446, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 301/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00301: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 302/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00302: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 303/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00303: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 304/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00304: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 305/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00305: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 79s 143us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 306/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00306: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 139us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 307/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00307: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 78s 141us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 308/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00308: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 309/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00309: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 310/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00310: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 311/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00311: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 312/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00312: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 313/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984 ETA: 2s - loss:\n",
      "Epoch 00313: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 314/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984 ETA: 0s - loss: 0\n",
      "Epoch 00314: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 315/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00315: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 79s 143us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 316/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00316: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 83s 151us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 317/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00317: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00318: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 319/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00319: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 320/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00320: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 80s 146us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 321/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00321: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 322/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00322: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 83s 151us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 323/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00323: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 87s 157us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 324/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00324: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 90s 163us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 325/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984 ETA: 0s\n",
      "Epoch 00325: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 86s 157us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 326/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00326: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 87s 157us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 327/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00327: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 328/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00328: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0088 - val_accuracy: 0.9979\n",
      "Epoch 329/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00329: val_loss improved from 0.00446 to 0.00446, saving model to C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\n",
      "549764/549764 [==============================] - 89s 162us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 330/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00330: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 80s 146us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 331/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00331: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 132us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 332/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984\n",
      "Epoch 00332: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 333/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984 ETA: 1s -\n",
      "Epoch 00333: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 334/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984\n",
      "Epoch 00334: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 335/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00335: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 336/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00336: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 337/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00337: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 338/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00338: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 339/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00339: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 72s 131us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 340/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00340: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 82s 148us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 341/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00341: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 87s 158us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 342/500\n",
      "549280/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00342: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 88s 160us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 343/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00343: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 85s 154us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 344/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00344: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 86s 156us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 345/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00345: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 87s 159us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 346/500\n",
      "549312/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00346: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 139us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 347/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00347: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 348/500\n",
      "549440/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00348: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 349/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00349: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 350/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984 E\n",
      "Epoch 00350: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 351/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00351: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 141us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 352/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00352: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 81s 147us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 353/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9985\n",
      "Epoch 00353: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 78s 142us/sample - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9991\n",
      "Epoch 354/500\n",
      "549248/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00354: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 355/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00355: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 356/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00356: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 357/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00357: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 358/500\n",
      "549344/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00358: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 359/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00359: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 360/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00360: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 361/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00361: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 362/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00362: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 363/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00363: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 82s 150us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 364/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00364: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 92s 167us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 365/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00365: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 93s 169us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 366/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00366: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 133s 243us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 367/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983\n",
      "Epoch 00367: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 134s 244us/sample - loss: 0.0061 - accuracy: 0.9983 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 368/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00368: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 133s 242us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 369/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00369: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 66s 121us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 370/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00370: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 69s 126us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 371/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00371: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 65s 117us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 372/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00372: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 373/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00373: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0049 - val_accuracy: 0.9992\n",
      "Epoch 374/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00374: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 375/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00375: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 376/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00376: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 377/500\n",
      "549600/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00377: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 134us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 378/500\n",
      "549408/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00378: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 379/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00379: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 380/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00380: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 381/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00381: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 382/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00382: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 383/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00383: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 384/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00384: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 385/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00385: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 386/500\n",
      "549472/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00386: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 387/500\n",
      "549376/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00387: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 388/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00388: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 389/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00389: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 80s 145us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 390/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00390: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 137us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 391/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00391: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 78s 141us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 392/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00392: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 74s 135us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 393/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00393: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 76s 138us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 394/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 00394: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 75s 136us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 395/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00395: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 140us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 396/500\n",
      "549696/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9985\n",
      "Epoch 00396: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 77s 139us/sample - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 397/500\n",
      "549760/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00397: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 90s 163us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 398/500\n",
      "549664/549764 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9984 ETA: 0s -\n",
      "Epoch 00398: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 92s 167us/sample - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 399/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9985\n",
      "Epoch 00399: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 92s 168us/sample - loss: 0.0058 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 400/500\n",
      "549632/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00400: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 89s 161us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 401/500\n",
      "549728/549764 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
      "Epoch 00401: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 89s 163us/sample - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 402/500\n",
      "549536/549764 [============================>.] - ETA: 0s - loss: 0.0057 - accuracy: 0.9985\n",
      "Epoch 00402: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 90s 163us/sample - loss: 0.0057 - accuracy: 0.9985 - val_loss: 0.0046 - val_accuracy: 0.9992\n",
      "Epoch 403/500\n",
      "549504/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9985\n",
      "Epoch 00403: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0047 - val_accuracy: 0.9992\n",
      "Epoch 404/500\n",
      "549568/549764 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9984\n",
      "Epoch 00404: val_loss did not improve from 0.00446\n",
      "549764/549764 [==============================] - 73s 133us/sample - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 00404: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs = 500,validation_split=0.33 ,verbose =1,callbacks=[es,mc,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 4, 256)            1280      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 133,889\n",
      "Trainable params: 133,377\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Recreate the exact same model, including its weights and the optimizer by loading our saved model.\n",
    "model = tf.keras.models.load_model(r\"C:\\Users\\Rajesh\\OneDrive\\Documents\\best_model_neww3.h5\")\n",
    "#Show the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: trainacc= 0.999,trainloss= 0.004, Test: testacc=  0.999, testloss= 0.005\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model \n",
    "trainloss,trainacc = model.evaluate(X_train,y_train,verbose=0)\n",
    "testloss,testacc = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('train: trainacc= %.3f,trainloss= %.3f, Test: testacc= % .3f, testloss= %.3f'%(trainacc,trainloss,testacc,testloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " y_predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00],\n",
       "       [0.00000000e+00],\n",
       "       [4.24130616e-35],\n",
       "       ...,\n",
       "       [0.00000000e+00],\n",
       "       [1.33215125e-14],\n",
       "       [0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.028629404952914994,\n",
       "  0.02609193581919555,\n",
       "  0.025177080306320387,\n",
       "  0.02444839802782789,\n",
       "  0.023185718818917612,\n",
       "  0.022744961607674846,\n",
       "  0.021828973970955134,\n",
       "  0.022120876888317854,\n",
       "  0.021146802507618093,\n",
       "  0.020757939896441032,\n",
       "  0.020133435762339787,\n",
       "  0.020199105117892704,\n",
       "  0.020014602427368047,\n",
       "  0.019691510234528677,\n",
       "  0.019772970619835174,\n",
       "  0.01890838508507875,\n",
       "  0.018709754133638422,\n",
       "  0.018339901053604495,\n",
       "  0.01804553820210515,\n",
       "  0.01815894543788629,\n",
       "  0.017710644281978532,\n",
       "  0.017520016679663842,\n",
       "  0.017192209492054064,\n",
       "  0.01697813291365534,\n",
       "  0.016979621844901177,\n",
       "  0.016693206242706607,\n",
       "  0.016503568013385424,\n",
       "  0.016203802867153595,\n",
       "  0.015921406973203246,\n",
       "  0.016135253171627565,\n",
       "  0.015793598107821213,\n",
       "  0.015900192758616587,\n",
       "  0.01609667437171284,\n",
       "  0.01544887330870375,\n",
       "  0.01595305408926226,\n",
       "  0.015220799617916458,\n",
       "  0.015353859702741472,\n",
       "  0.01531884849486068,\n",
       "  0.015311302421837316,\n",
       "  0.015581985061492429,\n",
       "  0.015191888346794018,\n",
       "  0.015142040404572787,\n",
       "  0.014747553259627542,\n",
       "  0.015115006707478952,\n",
       "  0.014780253278923865,\n",
       "  0.01469671200597974,\n",
       "  0.014924237594770151,\n",
       "  0.01468111398494946,\n",
       "  0.014788749716055477,\n",
       "  0.014324937291952576,\n",
       "  0.014499789468943857,\n",
       "  0.01433268602099377,\n",
       "  0.014196981201930156,\n",
       "  0.01402491495900115,\n",
       "  0.014065778720474858,\n",
       "  0.013525285088290253,\n",
       "  0.013847747008683953,\n",
       "  0.01398217478076793,\n",
       "  0.014202552748991827,\n",
       "  0.013715270528162102,\n",
       "  0.01364444464017363,\n",
       "  0.014078293056470037,\n",
       "  0.013881211834866802,\n",
       "  0.014670169735519678,\n",
       "  0.014725043373177857,\n",
       "  0.013773972687001625,\n",
       "  0.013397387412587732,\n",
       "  0.01358466645137828,\n",
       "  0.013185551315132991,\n",
       "  0.013425014947405936,\n",
       "  0.013753820587419424,\n",
       "  0.013290765570420419,\n",
       "  0.014192561027805563,\n",
       "  0.01359833284810466,\n",
       "  0.013577470481189699,\n",
       "  0.01412176570942784,\n",
       "  0.0134495564020111,\n",
       "  0.013055123092975775,\n",
       "  0.013174705568752063,\n",
       "  0.01310891746869768,\n",
       "  0.01290805895114681,\n",
       "  0.012984555808133949,\n",
       "  0.012837139655810183,\n",
       "  0.01307390271814706,\n",
       "  0.013050279806875715,\n",
       "  0.013603417710088737,\n",
       "  0.014174971590356645,\n",
       "  0.014072950724835808,\n",
       "  0.013749929207815035,\n",
       "  0.013376008179659081,\n",
       "  0.012883104356371551,\n",
       "  0.012713340240381999,\n",
       "  0.013123883396923646,\n",
       "  0.012735649128003606,\n",
       "  0.012891888036189063,\n",
       "  0.012297682531423434,\n",
       "  0.01266118687332173,\n",
       "  0.012559776885178698,\n",
       "  0.012421877173718038,\n",
       "  0.012262309837244321,\n",
       "  0.012026439740447663,\n",
       "  0.012132888438650832,\n",
       "  0.011872972732602922,\n",
       "  0.012049468660361985,\n",
       "  0.012131955039571523,\n",
       "  0.011942073393342254,\n",
       "  0.011950274818314063,\n",
       "  0.012924450368939898,\n",
       "  0.01228005422220941,\n",
       "  0.012023029396627173,\n",
       "  0.011994855717105948,\n",
       "  0.011640547888534141,\n",
       "  0.01156439043390291,\n",
       "  0.011705178093307471,\n",
       "  0.0114197996891773,\n",
       "  0.01128054878067928,\n",
       "  0.011313938135774719,\n",
       "  0.011233387456582087,\n",
       "  0.011277950477048028,\n",
       "  0.012164654724172361,\n",
       "  0.010854220905814846,\n",
       "  0.011960871759015319,\n",
       "  0.013100994140057194,\n",
       "  0.011332284600344173,\n",
       "  0.011340445150830979,\n",
       "  0.010832629116829733,\n",
       "  0.010703330662923479,\n",
       "  0.010816851807775614,\n",
       "  0.012384571647250646,\n",
       "  0.01142728072183864,\n",
       "  0.010913424608532228,\n",
       "  0.010697778177408523,\n",
       "  0.012334663519233877,\n",
       "  0.012169545845331458,\n",
       "  0.010850266165636727,\n",
       "  0.0113038889181909,\n",
       "  0.012005802183926346,\n",
       "  0.012052756468377347,\n",
       "  0.011881588869400096,\n",
       "  0.012167766250527075,\n",
       "  0.011872987042583818,\n",
       "  0.011753757571543157,\n",
       "  0.011635073209288879,\n",
       "  0.011655166189623556,\n",
       "  0.0115101881916677,\n",
       "  0.011393307348389677,\n",
       "  0.011640909130702802,\n",
       "  0.012915904758719954,\n",
       "  0.011322973435986806,\n",
       "  0.012020409248490824,\n",
       "  0.011844874878841649,\n",
       "  0.011052950303394983,\n",
       "  0.011854954675751837,\n",
       "  0.01173266803924927,\n",
       "  0.011860811081559931,\n",
       "  0.011564028037049222,\n",
       "  0.011603600469570765,\n",
       "  0.011316066444897147,\n",
       "  0.010926428242108556,\n",
       "  0.010403713446017,\n",
       "  0.011219542097685161,\n",
       "  0.011450913765971037,\n",
       "  0.012140761336243667,\n",
       "  0.010040080277913801,\n",
       "  0.008233648447841963,\n",
       "  0.00816671401724039,\n",
       "  0.007984888265482992,\n",
       "  0.008046289215554912,\n",
       "  0.007997605763476006,\n",
       "  0.007772775361922302,\n",
       "  0.007700030450780464,\n",
       "  0.007620305947739245,\n",
       "  0.007693191319642511,\n",
       "  0.0079142519120846,\n",
       "  0.0076247871538064095,\n",
       "  0.0074555202897028435,\n",
       "  0.007727939600189046,\n",
       "  0.007575991436725518,\n",
       "  0.007752447307150276,\n",
       "  0.007570841058806164,\n",
       "  0.007788682759806095,\n",
       "  0.0074973672940388805,\n",
       "  0.0075372266025767465,\n",
       "  0.007536694060070147,\n",
       "  0.007385935083687009,\n",
       "  0.007485803616289284,\n",
       "  0.0074693339737378316,\n",
       "  0.007529832502017608,\n",
       "  0.007401809038943863,\n",
       "  0.007425399566239949,\n",
       "  0.0071958409165887175,\n",
       "  0.007254243765897349,\n",
       "  0.007310519967132789,\n",
       "  0.007339563720959633,\n",
       "  0.007375426045758091,\n",
       "  0.007061676489805622,\n",
       "  0.007431339611137871,\n",
       "  0.006718854808299142,\n",
       "  0.006635842065135857,\n",
       "  0.006890313100851046,\n",
       "  0.006828623804257324,\n",
       "  0.006929596836463539,\n",
       "  0.006797097436209868,\n",
       "  0.0067332183057096625,\n",
       "  0.006425278933549837,\n",
       "  0.006817537476132055,\n",
       "  0.006680074948129957,\n",
       "  0.006706745169281517,\n",
       "  0.006457861873797608,\n",
       "  0.00671627645114209,\n",
       "  0.0066067108369959075,\n",
       "  0.0066757116686367675,\n",
       "  0.006525740657286113,\n",
       "  0.006833104375373812,\n",
       "  0.006746283132944687,\n",
       "  0.006478516272013036,\n",
       "  0.006559922558373731,\n",
       "  0.006485970835903426,\n",
       "  0.00659008470285183,\n",
       "  0.0065468690635417295,\n",
       "  0.006537080356655308,\n",
       "  0.006497727239235207,\n",
       "  0.00633756955921356,\n",
       "  0.00644862868481698,\n",
       "  0.006465649230932227,\n",
       "  0.00648392844294362,\n",
       "  0.006534694170123317,\n",
       "  0.006459368494588881,\n",
       "  0.0064944981484473295,\n",
       "  0.006408663948921315,\n",
       "  0.00647603359038654,\n",
       "  0.006439258876745439,\n",
       "  0.006491476863283813,\n",
       "  0.006470093948150773,\n",
       "  0.0063439716841266315,\n",
       "  0.006582372796458269,\n",
       "  0.006605976994704764,\n",
       "  0.006443329828093731,\n",
       "  0.006627778940311715,\n",
       "  0.006388546208421494,\n",
       "  0.006445506945163057,\n",
       "  0.0063358820545596495,\n",
       "  0.006241729857127286,\n",
       "  0.006277677360552327,\n",
       "  0.006131605930647924,\n",
       "  0.0061155781383855365,\n",
       "  0.0064896502934022665,\n",
       "  0.006362101570507691,\n",
       "  0.006331417400853004,\n",
       "  0.006327874934105327,\n",
       "  0.006361087336555363,\n",
       "  0.0061126272849531035,\n",
       "  0.006756237366915743,\n",
       "  0.006414986838534616,\n",
       "  0.0063731763117217816,\n",
       "  0.006272307066400764,\n",
       "  0.006419545646891982,\n",
       "  0.006355420812853716,\n",
       "  0.0062881763436435124,\n",
       "  0.006309990197655362,\n",
       "  0.006058477566866075,\n",
       "  0.006431353367842102,\n",
       "  0.006070885071154968,\n",
       "  0.006471074662727425,\n",
       "  0.006005069115107322,\n",
       "  0.005852252731654448,\n",
       "  0.006001439591025718,\n",
       "  0.006004865763187026,\n",
       "  0.006101855749047319,\n",
       "  0.005940412689951534,\n",
       "  0.006070905080991434,\n",
       "  0.005806612426987976,\n",
       "  0.005753600286574068,\n",
       "  0.005970833129410068,\n",
       "  0.0059313209736003595,\n",
       "  0.005963437473927201,\n",
       "  0.006147112564294105,\n",
       "  0.005802961655630813,\n",
       "  0.005917613115383103,\n",
       "  0.006105847988520008,\n",
       "  0.005858745324156295,\n",
       "  0.005877941823232445,\n",
       "  0.006041210262337929,\n",
       "  0.005875763511530573,\n",
       "  0.00586264206917532,\n",
       "  0.005922436166030982,\n",
       "  0.006057160341878722,\n",
       "  0.005971611992578798,\n",
       "  0.005991228996219983,\n",
       "  0.005991214172684334,\n",
       "  0.005968044139709685,\n",
       "  0.005908846238530206,\n",
       "  0.005888262725850224,\n",
       "  0.00569655687561538,\n",
       "  0.005857554414832908,\n",
       "  0.006039848782090713,\n",
       "  0.006071593244289716,\n",
       "  0.005958388979782903,\n",
       "  0.005989567142758864,\n",
       "  0.005997680875440019,\n",
       "  0.005872548056882883,\n",
       "  0.00586872944295284,\n",
       "  0.005783997600731372,\n",
       "  0.006004832728663082,\n",
       "  0.005830970183718727,\n",
       "  0.005931568851104988,\n",
       "  0.0060848763056851355,\n",
       "  0.005808894038573507,\n",
       "  0.0059125374728538965,\n",
       "  0.005792134052267386,\n",
       "  0.005829372479088348,\n",
       "  0.005880900916922797,\n",
       "  0.005949051653071827,\n",
       "  0.005894712764819982,\n",
       "  0.005866542314978117,\n",
       "  0.006096701554769905,\n",
       "  0.005854090757906132,\n",
       "  0.005836232279249846,\n",
       "  0.005993051956456439,\n",
       "  0.005800856167127186,\n",
       "  0.005815456092335763,\n",
       "  0.005725500957886829,\n",
       "  0.005887752886682137,\n",
       "  0.005890989694152955,\n",
       "  0.005851044411755728,\n",
       "  0.005972153823980465,\n",
       "  0.00575663146406998,\n",
       "  0.005844372721785207,\n",
       "  0.0059226244764395,\n",
       "  0.005947209980823798,\n",
       "  0.005871440762201189,\n",
       "  0.005748892841682576,\n",
       "  0.005985511799364685,\n",
       "  0.005594805731882882,\n",
       "  0.005815206632505587,\n",
       "  0.005788122770535567,\n",
       "  0.0059386532520613895,\n",
       "  0.005807574404337319,\n",
       "  0.005940823253589793,\n",
       "  0.005941767844149402,\n",
       "  0.0059927175927076025,\n",
       "  0.005960083536295773,\n",
       "  0.0059797308665747,\n",
       "  0.005861734384682548,\n",
       "  0.005935307241863563,\n",
       "  0.005759759432250948,\n",
       "  0.005762682812557978,\n",
       "  0.005728486062227993,\n",
       "  0.005689632567624868,\n",
       "  0.005882432525581844,\n",
       "  0.005816117319397739,\n",
       "  0.006050616570624056,\n",
       "  0.006063683055146601,\n",
       "  0.005886838613821442,\n",
       "  0.0058430858311360155,\n",
       "  0.0060133008488707194,\n",
       "  0.005945642856313767,\n",
       "  0.005880186607299975,\n",
       "  0.0059136938394142805,\n",
       "  0.005612572551875956,\n",
       "  0.0060727748454968075,\n",
       "  0.005925076179727817,\n",
       "  0.005700735643262564,\n",
       "  0.005885923683510221,\n",
       "  0.005965277026052478,\n",
       "  0.005954741073015472,\n",
       "  0.0060965177300357,\n",
       "  0.005881424973178087,\n",
       "  0.00581609939346353,\n",
       "  0.005906354820516,\n",
       "  0.005900556127804473,\n",
       "  0.00599421881101352,\n",
       "  0.005714769775232986,\n",
       "  0.005843095988841778,\n",
       "  0.005855124438617103,\n",
       "  0.005859567686446751,\n",
       "  0.00578342699702774,\n",
       "  0.005930553619633108,\n",
       "  0.0058635461350300564,\n",
       "  0.006044351162748576,\n",
       "  0.006091799470888546,\n",
       "  0.006051052810240737,\n",
       "  0.005879212990962679,\n",
       "  0.005927467955417336,\n",
       "  0.005869166533595083,\n",
       "  0.005865821999292037,\n",
       "  0.005690998943126422,\n",
       "  0.005887069054898211,\n",
       "  0.005830032854424352,\n",
       "  0.005771451145767735,\n",
       "  0.005922736808946782,\n",
       "  0.0059358633099849305,\n",
       "  0.00604521545491208,\n",
       "  0.005997366010618729,\n",
       "  0.00590094595091662,\n",
       "  0.006007084582201864,\n",
       "  0.0058181171332050766,\n",
       "  0.005994428541053329,\n",
       "  0.005776107538245272,\n",
       "  0.005760367157183878,\n",
       "  0.005843162635373609,\n",
       "  0.005670586765364517,\n",
       "  0.0058638496022358315,\n",
       "  0.005929467320139378],\n",
       " 'accuracy': [0.9914363,\n",
       "  0.991942,\n",
       "  0.992113,\n",
       "  0.9922458,\n",
       "  0.9926059,\n",
       "  0.9927005,\n",
       "  0.99297154,\n",
       "  0.99283147,\n",
       "  0.9931316,\n",
       "  0.99330986,\n",
       "  0.9934954,\n",
       "  0.99341536,\n",
       "  0.99346447,\n",
       "  0.9935027,\n",
       "  0.9936027,\n",
       "  0.9937064,\n",
       "  0.9937137,\n",
       "  0.99378276,\n",
       "  0.99377185,\n",
       "  0.99365544,\n",
       "  0.9939465,\n",
       "  0.99398834,\n",
       "  0.99399376,\n",
       "  0.9939847,\n",
       "  0.99394286,\n",
       "  0.99409384,\n",
       "  0.9941902,\n",
       "  0.99419934,\n",
       "  0.9942121,\n",
       "  0.9942011,\n",
       "  0.99423933,\n",
       "  0.99427027,\n",
       "  0.9941775,\n",
       "  0.9944121,\n",
       "  0.9942557,\n",
       "  0.994414,\n",
       "  0.9943521,\n",
       "  0.9944831,\n",
       "  0.9944267,\n",
       "  0.99439394,\n",
       "  0.99443036,\n",
       "  0.99438125,\n",
       "  0.9945176,\n",
       "  0.9943976,\n",
       "  0.9945686,\n",
       "  0.9945231,\n",
       "  0.9945067,\n",
       "  0.99449944,\n",
       "  0.9945686,\n",
       "  0.9946795,\n",
       "  0.9946577,\n",
       "  0.99464136,\n",
       "  0.99474865,\n",
       "  0.99481416,\n",
       "  0.9947614,\n",
       "  0.9949688,\n",
       "  0.99482507,\n",
       "  0.9948396,\n",
       "  0.9946759,\n",
       "  0.9948087,\n",
       "  0.9949269,\n",
       "  0.99479777,\n",
       "  0.9948614,\n",
       "  0.99459225,\n",
       "  0.99461406,\n",
       "  0.9948232,\n",
       "  0.99500877,\n",
       "  0.99487597,\n",
       "  0.9950397,\n",
       "  0.99496514,\n",
       "  0.99498874,\n",
       "  0.9950524,\n",
       "  0.994856,\n",
       "  0.99497056,\n",
       "  0.994996,\n",
       "  0.99474686,\n",
       "  0.99515975,\n",
       "  0.9952452,\n",
       "  0.99517065,\n",
       "  0.99524343,\n",
       "  0.9952725,\n",
       "  0.9952343,\n",
       "  0.99531436,\n",
       "  0.99520886,\n",
       "  0.9952689,\n",
       "  0.9950306,\n",
       "  0.99476504,\n",
       "  0.9949524,\n",
       "  0.9949178,\n",
       "  0.995107,\n",
       "  0.99521977,\n",
       "  0.9952179,\n",
       "  0.9951852,\n",
       "  0.9953908,\n",
       "  0.99537253,\n",
       "  0.99553263,\n",
       "  0.9953835,\n",
       "  0.9955108,\n",
       "  0.99550897,\n",
       "  0.9956781,\n",
       "  0.9956781,\n",
       "  0.9956563,\n",
       "  0.9958619,\n",
       "  0.9956545,\n",
       "  0.99568,\n",
       "  0.9956963,\n",
       "  0.9957836,\n",
       "  0.99533075,\n",
       "  0.9955563,\n",
       "  0.9956672,\n",
       "  0.9957982,\n",
       "  0.99590915,\n",
       "  0.9960401,\n",
       "  0.9959328,\n",
       "  0.99597466,\n",
       "  0.99607104,\n",
       "  0.9961838,\n",
       "  0.9960965,\n",
       "  0.9961784,\n",
       "  0.9956618,\n",
       "  0.9962839,\n",
       "  0.99578184,\n",
       "  0.9951124,\n",
       "  0.99599826,\n",
       "  0.9961183,\n",
       "  0.9964439,\n",
       "  0.99645483,\n",
       "  0.99641484,\n",
       "  0.9955908,\n",
       "  0.99608195,\n",
       "  0.9962802,\n",
       "  0.99640936,\n",
       "  0.9954963,\n",
       "  0.9956345,\n",
       "  0.9964676,\n",
       "  0.9961001,\n",
       "  0.9956527,\n",
       "  0.9956272,\n",
       "  0.9958455,\n",
       "  0.9957218,\n",
       "  0.99577457,\n",
       "  0.9959728,\n",
       "  0.995891,\n",
       "  0.9959528,\n",
       "  0.9959164,\n",
       "  0.99593097,\n",
       "  0.99593097,\n",
       "  0.99547625,\n",
       "  0.9961565,\n",
       "  0.9958346,\n",
       "  0.99599826,\n",
       "  0.99632025,\n",
       "  0.99574727,\n",
       "  0.9959437,\n",
       "  0.99589276,\n",
       "  0.9959055,\n",
       "  0.995911,\n",
       "  0.99613106,\n",
       "  0.99638027,\n",
       "  0.9965276,\n",
       "  0.9961456,\n",
       "  0.9962238,\n",
       "  0.9957327,\n",
       "  0.9964985,\n",
       "  0.9974007,\n",
       "  0.99742436,\n",
       "  0.99755716,\n",
       "  0.9975226,\n",
       "  0.9975462,\n",
       "  0.99764806,\n",
       "  0.9976572,\n",
       "  0.9977081,\n",
       "  0.9976899,\n",
       "  0.9976663,\n",
       "  0.9977008,\n",
       "  0.9976954,\n",
       "  0.99768263,\n",
       "  0.9977281,\n",
       "  0.99763715,\n",
       "  0.9977518,\n",
       "  0.99769354,\n",
       "  0.9977936,\n",
       "  0.9977772,\n",
       "  0.99779904,\n",
       "  0.99771357,\n",
       "  0.99780816,\n",
       "  0.99779,\n",
       "  0.99774086,\n",
       "  0.997739,\n",
       "  0.99772996,\n",
       "  0.9978136,\n",
       "  0.99783546,\n",
       "  0.99779725,\n",
       "  0.99775904,\n",
       "  0.99779177,\n",
       "  0.9978827,\n",
       "  0.9978682,\n",
       "  0.9980883,\n",
       "  0.99808097,\n",
       "  0.9980282,\n",
       "  0.99811554,\n",
       "  0.99802095,\n",
       "  0.99805737,\n",
       "  0.99809194,\n",
       "  0.9981501,\n",
       "  0.99811375,\n",
       "  0.998061,\n",
       "  0.9980956,\n",
       "  0.9981665,\n",
       "  0.99810827,\n",
       "  0.99818105,\n",
       "  0.9981556,\n",
       "  0.9981283,\n",
       "  0.99803185,\n",
       "  0.99808097,\n",
       "  0.9981992,\n",
       "  0.9981901,\n",
       "  0.9981301,\n",
       "  0.99819195,\n",
       "  0.99810284,\n",
       "  0.9981483,\n",
       "  0.99817556,\n",
       "  0.99825746,\n",
       "  0.9982011,\n",
       "  0.99822104,\n",
       "  0.9981592,\n",
       "  0.9981738,\n",
       "  0.99823016,\n",
       "  0.99821925,\n",
       "  0.99824107,\n",
       "  0.99819744,\n",
       "  0.99823016,\n",
       "  0.9981774,\n",
       "  0.99825925,\n",
       "  0.99824286,\n",
       "  0.99820834,\n",
       "  0.9981556,\n",
       "  0.9982229,\n",
       "  0.9981774,\n",
       "  0.9982356,\n",
       "  0.9982629,\n",
       "  0.9982283,\n",
       "  0.99829745,\n",
       "  0.99828655,\n",
       "  0.9983302,\n",
       "  0.99831384,\n",
       "  0.99818647,\n",
       "  0.9982465,\n",
       "  0.9982356,\n",
       "  0.99826473,\n",
       "  0.9982338,\n",
       "  0.9982774,\n",
       "  0.99818647,\n",
       "  0.99825746,\n",
       "  0.99819195,\n",
       "  0.9983011,\n",
       "  0.9982465,\n",
       "  0.9982738,\n",
       "  0.99828833,\n",
       "  0.9982847,\n",
       "  0.9983102,\n",
       "  0.99827015,\n",
       "  0.9983684,\n",
       "  0.99824834,\n",
       "  0.9983684,\n",
       "  0.99842477,\n",
       "  0.9983447,\n",
       "  0.9984011,\n",
       "  0.9983793,\n",
       "  0.99842477,\n",
       "  0.9983447,\n",
       "  0.9984502,\n",
       "  0.9984102,\n",
       "  0.9984266,\n",
       "  0.9983993,\n",
       "  0.99839383,\n",
       "  0.998372,\n",
       "  0.99839205,\n",
       "  0.99839383,\n",
       "  0.9983284,\n",
       "  0.9983957,\n",
       "  0.9984448,\n",
       "  0.9984102,\n",
       "  0.99843204,\n",
       "  0.9984339,\n",
       "  0.99841934,\n",
       "  0.99839747,\n",
       "  0.9983993,\n",
       "  0.998372,\n",
       "  0.998423,\n",
       "  0.99837565,\n",
       "  0.9984102,\n",
       "  0.9984448,\n",
       "  0.99841934,\n",
       "  0.99843204,\n",
       "  0.9983829,\n",
       "  0.9983848,\n",
       "  0.9983884,\n",
       "  0.9984448,\n",
       "  0.99844295,\n",
       "  0.99844295,\n",
       "  0.99846846,\n",
       "  0.9984375,\n",
       "  0.99837565,\n",
       "  0.9984612,\n",
       "  0.9983829,\n",
       "  0.99830836,\n",
       "  0.99845386,\n",
       "  0.9983829,\n",
       "  0.99838656,\n",
       "  0.99843204,\n",
       "  0.99847937,\n",
       "  0.9983848,\n",
       "  0.9984121,\n",
       "  0.99844295,\n",
       "  0.9983411,\n",
       "  0.99839747,\n",
       "  0.9984848,\n",
       "  0.9983848,\n",
       "  0.99844116,\n",
       "  0.99845207,\n",
       "  0.9984502,\n",
       "  0.9984339,\n",
       "  0.9984175,\n",
       "  0.9984121,\n",
       "  0.99840474,\n",
       "  0.99843204,\n",
       "  0.9984266,\n",
       "  0.99846846,\n",
       "  0.99844295,\n",
       "  0.99845934,\n",
       "  0.99844295,\n",
       "  0.9984157,\n",
       "  0.99844116,\n",
       "  0.9984393,\n",
       "  0.9984612,\n",
       "  0.9984448,\n",
       "  0.99844116,\n",
       "  0.99843204,\n",
       "  0.99844843,\n",
       "  0.99841386,\n",
       "  0.9984175,\n",
       "  0.99840844,\n",
       "  0.9984375,\n",
       "  0.9983684,\n",
       "  0.9984448,\n",
       "  0.9984903,\n",
       "  0.9985048,\n",
       "  0.99845934,\n",
       "  0.99843025,\n",
       "  0.998483,\n",
       "  0.9983848,\n",
       "  0.99845207,\n",
       "  0.99837023,\n",
       "  0.9983957,\n",
       "  0.9983957,\n",
       "  0.99840474,\n",
       "  0.9984575,\n",
       "  0.9983957,\n",
       "  0.99847937,\n",
       "  0.99840844,\n",
       "  0.99844843,\n",
       "  0.99845207,\n",
       "  0.99841386,\n",
       "  0.9984739,\n",
       "  0.99840474,\n",
       "  0.99833745,\n",
       "  0.99844116,\n",
       "  0.99847025,\n",
       "  0.9984157,\n",
       "  0.9984848,\n",
       "  0.9983902,\n",
       "  0.99849755,\n",
       "  0.998483,\n",
       "  0.99850297,\n",
       "  0.998423,\n",
       "  0.9984721,\n",
       "  0.99839747,\n",
       "  0.9984502,\n",
       "  0.99843204,\n",
       "  0.998423,\n",
       "  0.99837387,\n",
       "  0.99843204,\n",
       "  0.9984339,\n",
       "  0.9984739,\n",
       "  0.99847937,\n",
       "  0.9984939,\n",
       "  0.9984339,\n",
       "  0.99847573,\n",
       "  0.99842477,\n",
       "  0.99845386,\n",
       "  0.9984266,\n",
       "  0.99839747,\n",
       "  0.9984102,\n",
       "  0.9984957,\n",
       "  0.9984775,\n",
       "  0.9984284,\n",
       "  0.99840844,\n",
       "  0.9984957,\n",
       "  0.9984284,\n",
       "  0.9984066,\n",
       "  0.9984666,\n",
       "  0.9984884,\n",
       "  0.9983793],\n",
       " 'val_loss': [0.027255924171027165,\n",
       "  0.024736404439226145,\n",
       "  0.02361892133164768,\n",
       "  0.02164181377029621,\n",
       "  0.02111026629172459,\n",
       "  0.02096499022562869,\n",
       "  0.021883585007873296,\n",
       "  0.01902604627786469,\n",
       "  0.02114048815135442,\n",
       "  0.01826433377316883,\n",
       "  0.019921572998671457,\n",
       "  0.021661301089666494,\n",
       "  0.016888668662408922,\n",
       "  0.020976203947041777,\n",
       "  0.01736141433660763,\n",
       "  0.018404648200078963,\n",
       "  0.016877595638660328,\n",
       "  0.016652887192270174,\n",
       "  0.013820197772218983,\n",
       "  0.017272394079285547,\n",
       "  0.015578427945684838,\n",
       "  0.016226571639409396,\n",
       "  0.014611070759755646,\n",
       "  0.013851455321378771,\n",
       "  0.014217925064068292,\n",
       "  0.018639953977127637,\n",
       "  0.013647648217652868,\n",
       "  0.014568822046368895,\n",
       "  0.01615215823340554,\n",
       "  0.012831752475888495,\n",
       "  0.013840631720166715,\n",
       "  0.012856950727843956,\n",
       "  0.014572252010905505,\n",
       "  0.011961893616906352,\n",
       "  0.015188383254380126,\n",
       "  0.014040568203268801,\n",
       "  0.01223466852305303,\n",
       "  0.012614274896109326,\n",
       "  0.012764672700957904,\n",
       "  0.01175319436075093,\n",
       "  0.013489733126129522,\n",
       "  0.01295028192777968,\n",
       "  0.01588164937842149,\n",
       "  0.01128690365990912,\n",
       "  0.013628085374345813,\n",
       "  0.012818994085436514,\n",
       "  0.014933070211777965,\n",
       "  0.014484369742750827,\n",
       "  0.012276422958648229,\n",
       "  0.011376323899260993,\n",
       "  0.013233457940634264,\n",
       "  0.014930777939587747,\n",
       "  0.010607898860406124,\n",
       "  0.011181212878762795,\n",
       "  0.012394189743390557,\n",
       "  0.011731654967989794,\n",
       "  0.010601208733950599,\n",
       "  0.009455780375721933,\n",
       "  0.011575360905868082,\n",
       "  0.010909789882015282,\n",
       "  0.014388570068881659,\n",
       "  0.010451279978624666,\n",
       "  0.011684231142508692,\n",
       "  0.012018955230278006,\n",
       "  0.013297178285063604,\n",
       "  0.010666096255248761,\n",
       "  0.013279098423883544,\n",
       "  0.011395570884625962,\n",
       "  0.009980096876429732,\n",
       "  0.011849157881471416,\n",
       "  0.009913307359800658,\n",
       "  0.009690283712746986,\n",
       "  0.011030382836484245,\n",
       "  0.013118574280848451,\n",
       "  0.010207474534176442,\n",
       "  0.011254333302418065,\n",
       "  0.01178059310506927,\n",
       "  0.01161685371636436,\n",
       "  0.008827267758350245,\n",
       "  0.009019737881490597,\n",
       "  0.02648917672207636,\n",
       "  0.011032188522783636,\n",
       "  0.012395516719609789,\n",
       "  0.009081980754049838,\n",
       "  0.01019834603043157,\n",
       "  0.012534918851140024,\n",
       "  0.011585119765242168,\n",
       "  0.01127168040969137,\n",
       "  0.010631589817711994,\n",
       "  0.010364048422812156,\n",
       "  0.012610678525405272,\n",
       "  0.012033967389814519,\n",
       "  0.008793080614680517,\n",
       "  0.013422395925569708,\n",
       "  0.010485284317215082,\n",
       "  0.010703191714527289,\n",
       "  0.017805697837724198,\n",
       "  0.0088282223651087,\n",
       "  0.010998844837408695,\n",
       "  0.008464576816678674,\n",
       "  0.008239309342083882,\n",
       "  0.008586303255573616,\n",
       "  0.007532385655438162,\n",
       "  0.008377719871035687,\n",
       "  0.008136172916378737,\n",
       "  0.007673972421185652,\n",
       "  0.009895037878765675,\n",
       "  0.022161432819509025,\n",
       "  0.008236705097206727,\n",
       "  0.007945805132640229,\n",
       "  0.007774997835650262,\n",
       "  0.008343112235056897,\n",
       "  0.007156434185542602,\n",
       "  0.011161486190073322,\n",
       "  0.010103510450978686,\n",
       "  0.0065896893815697855,\n",
       "  0.009834710941345632,\n",
       "  0.008335960728789508,\n",
       "  0.006181442651785764,\n",
       "  0.007782372418245124,\n",
       "  0.008138274733722356,\n",
       "  0.009607641942395358,\n",
       "  0.008704117289217252,\n",
       "  0.007143139938494194,\n",
       "  0.008031044454719433,\n",
       "  0.008763434311803289,\n",
       "  0.00788520834535567,\n",
       "  0.005997315146556477,\n",
       "  0.009237686609687757,\n",
       "  0.006911227909793567,\n",
       "  0.006722170682903995,\n",
       "  0.009235908894287024,\n",
       "  0.012701355406397498,\n",
       "  0.007363948967145676,\n",
       "  0.007187944947262092,\n",
       "  0.009929449197552934,\n",
       "  0.00848986954672352,\n",
       "  0.007548363784981458,\n",
       "  0.007953253739599186,\n",
       "  0.01985874887288318,\n",
       "  0.008488838579452134,\n",
       "  0.007872758124622039,\n",
       "  0.01211916279829049,\n",
       "  0.01994796647140033,\n",
       "  0.012125364840214226,\n",
       "  0.009790773913799448,\n",
       "  0.008814349172755897,\n",
       "  0.009379464331435557,\n",
       "  0.0060426072618522154,\n",
       "  0.011686691804475355,\n",
       "  0.0073056173709941385,\n",
       "  0.009088763060509987,\n",
       "  0.012266166269801407,\n",
       "  0.008347898633695724,\n",
       "  0.011358558559800277,\n",
       "  0.00933593315715201,\n",
       "  0.007361617345132476,\n",
       "  0.006425118772551131,\n",
       "  0.00694369023372461,\n",
       "  0.006005849498226069,\n",
       "  0.007288430833290413,\n",
       "  0.0065914347446871845,\n",
       "  0.013695819926664124,\n",
       "  0.007723376591222469,\n",
       "  0.0060772468686588026,\n",
       "  0.00592443048443026,\n",
       "  0.0055910504514018146,\n",
       "  0.006040829291280183,\n",
       "  0.005327855140073406,\n",
       "  0.0053702802092401615,\n",
       "  0.005581537783863039,\n",
       "  0.005636203105488652,\n",
       "  0.0058521385570951935,\n",
       "  0.005433265495879709,\n",
       "  0.005654531375469746,\n",
       "  0.005571717578566197,\n",
       "  0.0058899758119618385,\n",
       "  0.005426808322509936,\n",
       "  0.00535009772270293,\n",
       "  0.0054204223480999614,\n",
       "  0.005222651741800407,\n",
       "  0.005170901910096426,\n",
       "  0.005154103051661534,\n",
       "  0.005135858984828113,\n",
       "  0.0060696324993626,\n",
       "  0.0050681542690191855,\n",
       "  0.00532879450565472,\n",
       "  0.005308309843856415,\n",
       "  0.005514506934896203,\n",
       "  0.005437966135032997,\n",
       "  0.0053249991829538825,\n",
       "  0.005108645611138109,\n",
       "  0.005371487513153138,\n",
       "  0.005065402790572816,\n",
       "  0.005481663488498683,\n",
       "  0.0052098342901309444,\n",
       "  0.004966157341136178,\n",
       "  0.005595992022591881,\n",
       "  0.005336840169188846,\n",
       "  0.005020677795765118,\n",
       "  0.004853931933329356,\n",
       "  0.005112320911873106,\n",
       "  0.005038402591815962,\n",
       "  0.004757008075058684,\n",
       "  0.0053733916073492255,\n",
       "  0.004883681068030768,\n",
       "  0.005205039799168228,\n",
       "  0.004858877988871341,\n",
       "  0.004928614465984101,\n",
       "  0.004841984744791189,\n",
       "  0.004898830287345384,\n",
       "  0.005188993231757374,\n",
       "  0.004909605307282242,\n",
       "  0.004957835089478687,\n",
       "  0.0049215946338678415,\n",
       "  0.004767521825282795,\n",
       "  0.005042760151649888,\n",
       "  0.005498312460496829,\n",
       "  0.00558596512125444,\n",
       "  0.004738426424785144,\n",
       "  0.004936360968825629,\n",
       "  0.004759503362683355,\n",
       "  0.00508920014471418,\n",
       "  0.004843400520939237,\n",
       "  0.004922186067779932,\n",
       "  0.005282366333725093,\n",
       "  0.004833318367263838,\n",
       "  0.004679472803799039,\n",
       "  0.0045737304675462975,\n",
       "  0.004794602309619743,\n",
       "  0.004641972306966237,\n",
       "  0.004637877385005628,\n",
       "  0.004633896270994396,\n",
       "  0.004567256476242498,\n",
       "  0.0048003596178081325,\n",
       "  0.004792555911833366,\n",
       "  0.004871637542167547,\n",
       "  0.005039922787712331,\n",
       "  0.0047983909718660395,\n",
       "  0.004880276343067014,\n",
       "  0.005116565986726714,\n",
       "  0.004973327687243288,\n",
       "  0.004994030944690985,\n",
       "  0.004858725690709289,\n",
       "  0.0050358499778031095,\n",
       "  0.004830763906407081,\n",
       "  0.00481080042543246,\n",
       "  0.004859488139444432,\n",
       "  0.005064418035290089,\n",
       "  0.004815115043833765,\n",
       "  0.004985079215541416,\n",
       "  0.004779126625491377,\n",
       "  0.00461959102621781,\n",
       "  0.004895286384329951,\n",
       "  0.004757876523162013,\n",
       "  0.00478803656039965,\n",
       "  0.004689369669286619,\n",
       "  0.004716141769175626,\n",
       "  0.004789341556054938,\n",
       "  0.004835329812039909,\n",
       "  0.004738346179432986,\n",
       "  0.00486363951787549,\n",
       "  0.0047989275418328725,\n",
       "  0.004740113998885024,\n",
       "  0.004556771882153495,\n",
       "  0.004734819433463195,\n",
       "  0.004501920178922865,\n",
       "  0.004866288792550422,\n",
       "  0.0047454768302392794,\n",
       "  0.004724224725212987,\n",
       "  0.004773329582461994,\n",
       "  0.0045558831174674335,\n",
       "  0.004637177895960845,\n",
       "  0.0045674461575911296,\n",
       "  0.004686469409064481,\n",
       "  0.004861308231637918,\n",
       "  0.004583261142482639,\n",
       "  0.0048664324201073954,\n",
       "  0.004690069568964194,\n",
       "  0.004586473295243127,\n",
       "  0.004691415024085848,\n",
       "  0.0047884362916248285,\n",
       "  0.00468202534001741,\n",
       "  0.008320693647493608,\n",
       "  0.004793217659882041,\n",
       "  0.004891552239963986,\n",
       "  0.004715175793120856,\n",
       "  0.004632368246225833,\n",
       "  0.00463376838809386,\n",
       "  0.004587890400010855,\n",
       "  0.004654568207966036,\n",
       "  0.004612829948696603,\n",
       "  0.004498998241759611,\n",
       "  0.004720721665909913,\n",
       "  0.004539614169000595,\n",
       "  0.004773084672101393,\n",
       "  0.004560943076681724,\n",
       "  0.0045612884660845565,\n",
       "  0.0047107770841252295,\n",
       "  0.004462955467482284,\n",
       "  0.0046436674403413855,\n",
       "  0.004715668294367647,\n",
       "  0.004690780703438668,\n",
       "  0.004795032675081437,\n",
       "  0.004636644096808325,\n",
       "  0.004782901431608815,\n",
       "  0.004707440096333508,\n",
       "  0.004689223634995837,\n",
       "  0.004643856311881114,\n",
       "  0.004638595317964632,\n",
       "  0.004593137336101417,\n",
       "  0.004678357986130293,\n",
       "  0.004707226255034275,\n",
       "  0.004568537341668211,\n",
       "  0.004728602355814175,\n",
       "  0.004732843546683406,\n",
       "  0.00461646705827518,\n",
       "  0.004761757576896322,\n",
       "  0.004566564778996854,\n",
       "  0.004569241591563699,\n",
       "  0.004724172877581383,\n",
       "  0.004671309769855848,\n",
       "  0.004689104568752378,\n",
       "  0.004719402329481339,\n",
       "  0.004497778680240253,\n",
       "  0.004551936027623155,\n",
       "  0.004817062355597792,\n",
       "  0.00881131813929209,\n",
       "  0.0044584521568860405,\n",
       "  0.004700928421343559,\n",
       "  0.004656383686730446,\n",
       "  0.004575193013674208,\n",
       "  0.004576710655238507,\n",
       "  0.0046407584494502965,\n",
       "  0.004521202460337697,\n",
       "  0.004505377517779612,\n",
       "  0.004665305838871018,\n",
       "  0.004628990622852467,\n",
       "  0.004829211678473243,\n",
       "  0.004516799236874593,\n",
       "  0.004545197820005989,\n",
       "  0.0047551037318734855,\n",
       "  0.004604400953444882,\n",
       "  0.004792749868817096,\n",
       "  0.004684623099889522,\n",
       "  0.00463335292221781,\n",
       "  0.004731521294486128,\n",
       "  0.0045564403667161845,\n",
       "  0.004671229082921781,\n",
       "  0.004716518135974151,\n",
       "  0.004528569574882289,\n",
       "  0.004727932233165477,\n",
       "  0.00467360142783271,\n",
       "  0.0047800801286123846,\n",
       "  0.004624759569147128,\n",
       "  0.0046203207486377506,\n",
       "  0.0046412426329473224,\n",
       "  0.004662825569041422,\n",
       "  0.004643857111488213,\n",
       "  0.004645281909432306,\n",
       "  0.0046490113112830885,\n",
       "  0.004716930707553583,\n",
       "  0.004691906747234901,\n",
       "  0.00465974830810061,\n",
       "  0.004774928695211785,\n",
       "  0.004611863222730275,\n",
       "  0.004713283253870319,\n",
       "  0.00473156164898569,\n",
       "  0.004654838262867544,\n",
       "  0.004605470121629565,\n",
       "  0.004732564135591473,\n",
       "  0.004715989999805733,\n",
       "  0.004861814045693325,\n",
       "  0.004696387750073041,\n",
       "  0.00465579765710762,\n",
       "  0.004567543279652933,\n",
       "  0.004615312343707949,\n",
       "  0.004650898453241203,\n",
       "  0.004683255112521528,\n",
       "  0.004489995128553391,\n",
       "  0.0046900356819828655,\n",
       "  0.004752325882769077,\n",
       "  0.004681176469599103,\n",
       "  0.0047507179574084474,\n",
       "  0.004578384748141838,\n",
       "  0.008509569796042893,\n",
       "  0.0046322199472967635,\n",
       "  0.00476474848866575,\n",
       "  0.004468893368061605,\n",
       "  0.004613180885934852,\n",
       "  0.004719783455159954,\n",
       "  0.004603849105831267,\n",
       "  0.004731922453977231,\n",
       "  0.004692663999574842,\n",
       "  0.004679444543965409,\n",
       "  0.004641996924376312,\n",
       "  0.004672805265766948,\n",
       "  0.004525201987949928,\n",
       "  0.004629162586842931,\n",
       "  0.00481022601343872,\n",
       "  0.004639926406732636,\n",
       "  0.004627748411626119,\n",
       "  0.004695686255335082,\n",
       "  0.004781529319740644],\n",
       " 'val_accuracy': [0.99191594,\n",
       "  0.99206364,\n",
       "  0.9923628,\n",
       "  0.99371445,\n",
       "  0.9930202,\n",
       "  0.9930017,\n",
       "  0.9927173,\n",
       "  0.9937809,\n",
       "  0.9934818,\n",
       "  0.9936184,\n",
       "  0.9940505,\n",
       "  0.9935224,\n",
       "  0.9945454,\n",
       "  0.9936591,\n",
       "  0.9938954,\n",
       "  0.99359995,\n",
       "  0.99423146,\n",
       "  0.9938954,\n",
       "  0.9940099,\n",
       "  0.994309,\n",
       "  0.9943201,\n",
       "  0.9945639,\n",
       "  0.99446416,\n",
       "  0.9947928,\n",
       "  0.9940247,\n",
       "  0.9938474,\n",
       "  0.9947854,\n",
       "  0.9942684,\n",
       "  0.99413544,\n",
       "  0.99503654,\n",
       "  0.9949258,\n",
       "  0.994069,\n",
       "  0.99446416,\n",
       "  0.99461555,\n",
       "  0.9946968,\n",
       "  0.99419826,\n",
       "  0.9946488,\n",
       "  0.99515474,\n",
       "  0.99499595,\n",
       "  0.995236,\n",
       "  0.994586,\n",
       "  0.99437183,\n",
       "  0.9949331,\n",
       "  0.9950661,\n",
       "  0.994586,\n",
       "  0.9942832,\n",
       "  0.9966578,\n",
       "  0.99488515,\n",
       "  0.99504024,\n",
       "  0.9947965,\n",
       "  0.9948113,\n",
       "  0.9941539,\n",
       "  0.99475586,\n",
       "  0.99642515,\n",
       "  0.99461925,\n",
       "  0.9951178,\n",
       "  0.9952101,\n",
       "  0.99604475,\n",
       "  0.99447525,\n",
       "  0.99486667,\n",
       "  0.9948187,\n",
       "  0.9953098,\n",
       "  0.995092,\n",
       "  0.9952397,\n",
       "  0.9942204,\n",
       "  0.9950587,\n",
       "  0.99775094,\n",
       "  0.995188,\n",
       "  0.99512887,\n",
       "  0.99764013,\n",
       "  0.99525076,\n",
       "  0.99877024,\n",
       "  0.99846,\n",
       "  0.9981535,\n",
       "  0.9949775,\n",
       "  0.99502176,\n",
       "  0.9979467,\n",
       "  0.9985597,\n",
       "  0.99654335,\n",
       "  0.997799,\n",
       "  0.9945786,\n",
       "  0.99477434,\n",
       "  0.99471897,\n",
       "  0.99759215,\n",
       "  0.9950513,\n",
       "  0.9948519,\n",
       "  0.9951991,\n",
       "  0.9951178,\n",
       "  0.99525815,\n",
       "  0.99696434,\n",
       "  0.99514365,\n",
       "  0.99797255,\n",
       "  0.9960706,\n",
       "  0.9951215,\n",
       "  0.9944863,\n",
       "  0.9951141,\n",
       "  0.9913251,\n",
       "  0.9987037,\n",
       "  0.99502915,\n",
       "  0.9960891,\n",
       "  0.9962257,\n",
       "  0.99525815,\n",
       "  0.9981535,\n",
       "  0.99821997,\n",
       "  0.99885887,\n",
       "  0.99758846,\n",
       "  0.99525815,\n",
       "  0.9869968,\n",
       "  0.9984748,\n",
       "  0.9986151,\n",
       "  0.99785066,\n",
       "  0.9953579,\n",
       "  0.99889946,\n",
       "  0.9962811,\n",
       "  0.9977916,\n",
       "  0.998833,\n",
       "  0.9980279,\n",
       "  0.9958527,\n",
       "  0.9989844,\n",
       "  0.9984341,\n",
       "  0.99799836,\n",
       "  0.99510676,\n",
       "  0.9975294,\n",
       "  0.998929,\n",
       "  0.9986668,\n",
       "  0.9962405,\n",
       "  0.99526924,\n",
       "  0.9987776,\n",
       "  0.99488884,\n",
       "  0.99821997,\n",
       "  0.9988515,\n",
       "  0.9987776,\n",
       "  0.9953209,\n",
       "  0.9984083,\n",
       "  0.9983603,\n",
       "  0.9950513,\n",
       "  0.9953874,\n",
       "  0.9987296,\n",
       "  0.99887735,\n",
       "  0.9858557,\n",
       "  0.9960263,\n",
       "  0.9956016,\n",
       "  0.99525076,\n",
       "  0.9952434,\n",
       "  0.99748504,\n",
       "  0.99526185,\n",
       "  0.99539846,\n",
       "  0.9984415,\n",
       "  0.99879974,\n",
       "  0.9952323,\n",
       "  0.9989401,\n",
       "  0.99875176,\n",
       "  0.995609,\n",
       "  0.99748874,\n",
       "  0.9979873,\n",
       "  0.995284,\n",
       "  0.99875546,\n",
       "  0.998833,\n",
       "  0.9988108,\n",
       "  0.9988884,\n",
       "  0.9987813,\n",
       "  0.9987,\n",
       "  0.9962774,\n",
       "  0.9984415,\n",
       "  0.9988182,\n",
       "  0.99901396,\n",
       "  0.9989955,\n",
       "  0.9988478,\n",
       "  0.9990472,\n",
       "  0.9990546,\n",
       "  0.99886256,\n",
       "  0.99903613,\n",
       "  0.9988256,\n",
       "  0.998881,\n",
       "  0.99887365,\n",
       "  0.9989364,\n",
       "  0.99891055,\n",
       "  0.998881,\n",
       "  0.9989475,\n",
       "  0.99891424,\n",
       "  0.9989475,\n",
       "  0.9990841,\n",
       "  0.99891794,\n",
       "  0.9989364,\n",
       "  0.99891794,\n",
       "  0.99891794,\n",
       "  0.9989438,\n",
       "  0.9989992,\n",
       "  0.99892163,\n",
       "  0.9989918,\n",
       "  0.9989512,\n",
       "  0.99912107,\n",
       "  0.998929,\n",
       "  0.99902135,\n",
       "  0.99901766,\n",
       "  0.9990029,\n",
       "  0.99905825,\n",
       "  0.9989881,\n",
       "  0.99900657,\n",
       "  0.99900657,\n",
       "  0.99903244,\n",
       "  0.99901396,\n",
       "  0.99900657,\n",
       "  0.9989844,\n",
       "  0.99901026,\n",
       "  0.99903613,\n",
       "  0.99903613,\n",
       "  0.9990546,\n",
       "  0.9990435,\n",
       "  0.99902874,\n",
       "  0.99901396,\n",
       "  0.99901396,\n",
       "  0.99906933,\n",
       "  0.99903244,\n",
       "  0.99901396,\n",
       "  0.9990546,\n",
       "  0.99902505,\n",
       "  0.9989918,\n",
       "  0.99891424,\n",
       "  0.99916905,\n",
       "  0.99906564,\n",
       "  0.99916536,\n",
       "  0.9991912,\n",
       "  0.9990546,\n",
       "  0.99917275,\n",
       "  0.99901026,\n",
       "  0.99912477,\n",
       "  0.9990546,\n",
       "  0.9990546,\n",
       "  0.9990472,\n",
       "  0.9990509,\n",
       "  0.9991506,\n",
       "  0.9992097,\n",
       "  0.9991986,\n",
       "  0.9991986,\n",
       "  0.9990472,\n",
       "  0.9991912,\n",
       "  0.9991949,\n",
       "  0.99918383,\n",
       "  0.99917644,\n",
       "  0.99913585,\n",
       "  0.99917275,\n",
       "  0.9992023,\n",
       "  0.99918014,\n",
       "  0.99916166,\n",
       "  0.999206,\n",
       "  0.99918383,\n",
       "  0.9992023,\n",
       "  0.9991986,\n",
       "  0.99913216,\n",
       "  0.9991912,\n",
       "  0.9992134,\n",
       "  0.9992171,\n",
       "  0.99905825,\n",
       "  0.9992134,\n",
       "  0.999206,\n",
       "  0.9991949,\n",
       "  0.9992023,\n",
       "  0.9990841,\n",
       "  0.9991912,\n",
       "  0.99905825,\n",
       "  0.99912846,\n",
       "  0.99917644,\n",
       "  0.9991949,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992134,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.9992134,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9981793,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.99915797,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9991986,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992134,\n",
       "  0.9992023,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992208,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9979393,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992208,\n",
       "  0.999206,\n",
       "  0.9992134,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.9992208,\n",
       "  0.9991986,\n",
       "  0.9990989,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992097,\n",
       "  0.9992023,\n",
       "  0.9991986,\n",
       "  0.9992023,\n",
       "  0.9991986,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9991986,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992171,\n",
       "  0.9980316,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.9992023,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992208,\n",
       "  0.9992023,\n",
       "  0.99915797,\n",
       "  0.999206,\n",
       "  0.999206,\n",
       "  0.9992023,\n",
       "  0.999206],\n",
       " 'lr': [0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.001,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  0.000100000005,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-05,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-06,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-07,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08,\n",
       "  1.0000001e-08]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9914363, 0.991942, 0.992113, 0.9922458, 0.9926059, 0.9927005, 0.99297154, 0.99283147, 0.9931316, 0.99330986, 0.9934954, 0.99341536, 0.99346447, 0.9935027, 0.9936027, 0.9937064, 0.9937137, 0.99378276, 0.99377185, 0.99365544, 0.9939465, 0.99398834, 0.99399376, 0.9939847, 0.99394286, 0.99409384, 0.9941902, 0.99419934, 0.9942121, 0.9942011, 0.99423933, 0.99427027, 0.9941775, 0.9944121, 0.9942557, 0.994414, 0.9943521, 0.9944831, 0.9944267, 0.99439394, 0.99443036, 0.99438125, 0.9945176, 0.9943976, 0.9945686, 0.9945231, 0.9945067, 0.99449944, 0.9945686, 0.9946795, 0.9946577, 0.99464136, 0.99474865, 0.99481416, 0.9947614, 0.9949688, 0.99482507, 0.9948396, 0.9946759, 0.9948087, 0.9949269, 0.99479777, 0.9948614, 0.99459225, 0.99461406, 0.9948232, 0.99500877, 0.99487597, 0.9950397, 0.99496514, 0.99498874, 0.9950524, 0.994856, 0.99497056, 0.994996, 0.99474686, 0.99515975, 0.9952452, 0.99517065, 0.99524343, 0.9952725, 0.9952343, 0.99531436, 0.99520886, 0.9952689, 0.9950306, 0.99476504, 0.9949524, 0.9949178, 0.995107, 0.99521977, 0.9952179, 0.9951852, 0.9953908, 0.99537253, 0.99553263, 0.9953835, 0.9955108, 0.99550897, 0.9956781, 0.9956781, 0.9956563, 0.9958619, 0.9956545, 0.99568, 0.9956963, 0.9957836, 0.99533075, 0.9955563, 0.9956672, 0.9957982, 0.99590915, 0.9960401, 0.9959328, 0.99597466, 0.99607104, 0.9961838, 0.9960965, 0.9961784, 0.9956618, 0.9962839, 0.99578184, 0.9951124, 0.99599826, 0.9961183, 0.9964439, 0.99645483, 0.99641484, 0.9955908, 0.99608195, 0.9962802, 0.99640936, 0.9954963, 0.9956345, 0.9964676, 0.9961001, 0.9956527, 0.9956272, 0.9958455, 0.9957218, 0.99577457, 0.9959728, 0.995891, 0.9959528, 0.9959164, 0.99593097, 0.99593097, 0.99547625, 0.9961565, 0.9958346, 0.99599826, 0.99632025, 0.99574727, 0.9959437, 0.99589276, 0.9959055, 0.995911, 0.99613106, 0.99638027, 0.9965276, 0.9961456, 0.9962238, 0.9957327, 0.9964985, 0.9974007, 0.99742436, 0.99755716, 0.9975226, 0.9975462, 0.99764806, 0.9976572, 0.9977081, 0.9976899, 0.9976663, 0.9977008, 0.9976954, 0.99768263, 0.9977281, 0.99763715, 0.9977518, 0.99769354, 0.9977936, 0.9977772, 0.99779904, 0.99771357, 0.99780816, 0.99779, 0.99774086, 0.997739, 0.99772996, 0.9978136, 0.99783546, 0.99779725, 0.99775904, 0.99779177, 0.9978827, 0.9978682, 0.9980883, 0.99808097, 0.9980282, 0.99811554, 0.99802095, 0.99805737, 0.99809194, 0.9981501, 0.99811375, 0.998061, 0.9980956, 0.9981665, 0.99810827, 0.99818105, 0.9981556, 0.9981283, 0.99803185, 0.99808097, 0.9981992, 0.9981901, 0.9981301, 0.99819195, 0.99810284, 0.9981483, 0.99817556, 0.99825746, 0.9982011, 0.99822104, 0.9981592, 0.9981738, 0.99823016, 0.99821925, 0.99824107, 0.99819744, 0.99823016, 0.9981774, 0.99825925, 0.99824286, 0.99820834, 0.9981556, 0.9982229, 0.9981774, 0.9982356, 0.9982629, 0.9982283, 0.99829745, 0.99828655, 0.9983302, 0.99831384, 0.99818647, 0.9982465, 0.9982356, 0.99826473, 0.9982338, 0.9982774, 0.99818647, 0.99825746, 0.99819195, 0.9983011, 0.9982465, 0.9982738, 0.99828833, 0.9982847, 0.9983102, 0.99827015, 0.9983684, 0.99824834, 0.9983684, 0.99842477, 0.9983447, 0.9984011, 0.9983793, 0.99842477, 0.9983447, 0.9984502, 0.9984102, 0.9984266, 0.9983993, 0.99839383, 0.998372, 0.99839205, 0.99839383, 0.9983284, 0.9983957, 0.9984448, 0.9984102, 0.99843204, 0.9984339, 0.99841934, 0.99839747, 0.9983993, 0.998372, 0.998423, 0.99837565, 0.9984102, 0.9984448, 0.99841934, 0.99843204, 0.9983829, 0.9983848, 0.9983884, 0.9984448, 0.99844295, 0.99844295, 0.99846846, 0.9984375, 0.99837565, 0.9984612, 0.9983829, 0.99830836, 0.99845386, 0.9983829, 0.99838656, 0.99843204, 0.99847937, 0.9983848, 0.9984121, 0.99844295, 0.9983411, 0.99839747, 0.9984848, 0.9983848, 0.99844116, 0.99845207, 0.9984502, 0.9984339, 0.9984175, 0.9984121, 0.99840474, 0.99843204, 0.9984266, 0.99846846, 0.99844295, 0.99845934, 0.99844295, 0.9984157, 0.99844116, 0.9984393, 0.9984612, 0.9984448, 0.99844116, 0.99843204, 0.99844843, 0.99841386, 0.9984175, 0.99840844, 0.9984375, 0.9983684, 0.9984448, 0.9984903, 0.9985048, 0.99845934, 0.99843025, 0.998483, 0.9983848, 0.99845207, 0.99837023, 0.9983957, 0.9983957, 0.99840474, 0.9984575, 0.9983957, 0.99847937, 0.99840844, 0.99844843, 0.99845207, 0.99841386, 0.9984739, 0.99840474, 0.99833745, 0.99844116, 0.99847025, 0.9984157, 0.9984848, 0.9983902, 0.99849755, 0.998483, 0.99850297, 0.998423, 0.9984721, 0.99839747, 0.9984502, 0.99843204, 0.998423, 0.99837387, 0.99843204, 0.9984339, 0.9984739, 0.99847937, 0.9984939, 0.9984339, 0.99847573, 0.99842477, 0.99845386, 0.9984266, 0.99839747, 0.9984102, 0.9984957, 0.9984775, 0.9984284, 0.99840844, 0.9984957, 0.9984284, 0.9984066, 0.9984666, 0.9984884, 0.9983793]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurve(history,epoch):\n",
    "  #ploting training & validation accuracy values\n",
    "  epoch_range = range(1,epoch+1)\n",
    "  plt.plot(epoch_range,history.history['accuracy'])\n",
    "  plt.plot(epoch_range,history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train','test'],loc='right')\n",
    "  plt.show()\n",
    "\n",
    "#plot training & validation loss values\n",
    "  plt.plot(epoch_range,history.history['loss'])\n",
    "  plt.plot(epoch_range,history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train','test'],loc='right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningCurve(history,404)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = np.asarray(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[199701     59]\n",
      " [   120   5257]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199760\n",
      "           1       0.99      0.98      0.98      5377\n",
      "\n",
      "    accuracy                           1.00    205137\n",
      "   macro avg       0.99      0.99      0.99    205137\n",
      "weighted avg       1.00      1.00      1.00    205137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,y_predict.round()))\n",
    "print(classification_report(y_test.round(),y_predict.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[199701,     59],\n",
       "       [   120,   5257]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conff = confusion_matrix(y_test,y_predict.round())\n",
    "conff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Confusion matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "classes = [0,1]\n",
    "plt.imshow(conff,interpolation='nearest',cmap=plt.cm.Greens)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks,classes)\n",
    "plt.yticks(tick_marks,classes)\n",
    "accuracy = metrics.accuracy_score(y_test,y_predict.round())\n",
    "misclass =1-accuracy\n",
    "fmt ='d'\n",
    "thresh = conff.max()/2\n",
    "for i, j in itertools.product(range(conff.shape[0]),range(conff.shape[1])):\n",
    "  plt.text(j,i,format(conff[i,j],fmt),horizontalalignment='center', color=\"indigo\" if conff[i,j]>thresh else \"blue\")\n",
    "  plt.tight_layout()\n",
    "  plt.ylabel('True label')\n",
    "  #plt.xlabel('Predicted label')\n",
    "  plt.xlabel('Predicted label ( 1-True,0-False )\\naccuracy={:0.3f}; misclass={:0.3f}'.format(accuracy, misclass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = true_positives = 5257\n",
    "TN = true_negatives = 554366\n",
    "FP = false_positives = 59\n",
    "FN = false_negatives = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flase positive rate of this model is0.0001\n"
     ]
    }
   ],
   "source": [
    "#False Positive rate\n",
    "FPR = FP/(TN+FP)\n",
    "print(\"The flase positive rate of this model is{:.4f}\".format(FPR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The true negative rate of this model is0.9999\n"
     ]
    }
   ],
   "source": [
    "#true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "print(\"The true negative rate of this model is{:.4f}\".format(TNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is Deep Learning classifier\n",
      "The accuracy is 1.00\n",
      "The precision is 0.99\n",
      "The recall is 0.98\n",
      "The F1-Score is 0.98\n",
      "The Matthews correlation coefficient is0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the classifier \n",
    "# printing every score of the classifier \n",
    "# scoring in anything \n",
    "y_pred = y_predict.round()\n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "print(\"The model used is Deep Learning classifier\")\n",
    "acc = accuracy_score(y_test, y_pred) \n",
    "print(\"The accuracy is {:.2f}\".format(acc)) \n",
    "\n",
    "prec = precision_score(y_test, y_pred) \n",
    "print(\"The precision is {:.2f}\".format(prec)) \n",
    "\n",
    "rec = recall_score(y_test, y_pred) \n",
    "print(\"The recall is {:.2f}\".format(rec)) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print(\"The F1-Score is {:.2f}\".format(f1)) \n",
    "\n",
    "MCC = matthews_corrcoef(y_test, y_pred) \n",
    "print(\"The Matthews correlation coefficient is{:.2f}\".format(MCC)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model used is Deep Learning classifier\n",
      "The accuracy is 0.999127\n",
      "The precision is 0.988901\n",
      "The recall is 0.977683\n",
      "The F1-Score is 0.983260\n",
      "The Matthews correlation coefficient is0.982829\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the classifier \n",
    "# printing every score of the classifier \n",
    "y_pred = y_predict.round()\n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "from sklearn.metrics import f1_score, matthews_corrcoef \n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "\n",
    "print(\"The model used is Deep Learning classifier\")\n",
    "acc = accuracy_score(y_test, y_pred) \n",
    "print(\"The accuracy is {:.6f}\".format(acc)) \n",
    "\n",
    "prec = precision_score(y_test, y_pred) \n",
    "print(\"The precision is {:.6f}\".format(prec)) \n",
    "\n",
    "rec = recall_score(y_test, y_pred) \n",
    "print(\"The recall is {:.6f}\".format(rec)) \n",
    "\n",
    "f1 = f1_score(y_test, y_pred) \n",
    "print(\"The F1-Score is {:.6f}\".format(f1)) \n",
    "\n",
    "MCC = matthews_corrcoef(y_test, y_pred) \n",
    "print(\"The Matthews correlation coefficient is{:.6f}\".format(MCC)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "FPRs, TPRs, _ = metrics.roc_curve(y_test, y_proba)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(FPRs, TPRs, color='red',lw=2, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label=\"Mean\")\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(\"Scikit-learn's ROC curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit's ROC-AUC score of DL model is  1.000\n"
     ]
    }
   ],
   "source": [
    "auc_score = metrics.roc_auc_score(y_test, y_proba)\n",
    "print(f\"Scikit's ROC-AUC score of DL model is {auc_score: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DL: f1=0.983 auc=1.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# precision-recall curve and f1\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "# keep probabilities for the positive outcome only\n",
    "#lr_probs = y_proba[:, 1]\n",
    "# predict class values\n",
    "yhat = y_predict\n",
    "lr_precision, lr_recall = prec,rec\n",
    "lr_f1,lr_auc = f1,auc_score\n",
    "# summarize scores\n",
    "print('DL: f1=%.3f auc=%.3f' % (lr_f1,lr_auc))\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "pyplot.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "pyplot.plot(lr_recall, lr_precision, marker='.', label='DL')\n",
    "# axis labels\n",
    "pyplot.xlabel('Recall')\n",
    "pyplot.ylabel('Precision')\n",
    "# show the legend\n",
    "pyplot.legend()\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
